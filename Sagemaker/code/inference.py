"""
SageMaker Async Inference for Speech Emotion Recognition (SER)
ìŒì„± ê°ì • ì¸ì‹ì„ ìœ„í•œ SageMaker ë¹„ë™ê¸° ì¶”ë¡  ì—”ë“œí¬ì¸íŠ¸
"""
import json
import os
import sys
import logging
import torch
import numpy as np
import librosa
import soundfile as sf
from io import BytesIO
import base64
from pathlib import Path
from typing import Dict, Any, List, Optional
import tarfile
import tempfile

# ë¡œê¹… ì„¤ì • (ë¨¼ì € ì„¤ì •)
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# SageMaker í™˜ê²½ì—ì„œ ëª¨ë“ˆ ê²½ë¡œ ì„¤ì •
def setup_module_paths():
    """SageMaker ë°°í¬ í™˜ê²½ì—ì„œ ëª¨ë“ˆ ê²½ë¡œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
    current_dir = Path(__file__).parent
    
    # ê°€ëŠ¥í•œ ëª¨ë“  ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€
    paths_to_add = [
        str(current_dir),
        str(current_dir.parent),
        str(current_dir.parent.parent),
        '/opt/ml/code',
        '/opt/ml/code/SER',
        '/opt/ml/code/SER/Sagemaker/code',
    ]
    
    for path in paths_to_add:
        if os.path.exists(path) and path not in sys.path:
            sys.path.insert(0, path)
    
    logger.info(f"ğŸ“‚ Module paths configured. Current working directory: {os.getcwd()}")

# ê²½ë¡œ ì„¤ì • ì‹¤í–‰
setup_module_paths()

from transformers import Wav2Vec2Processor, Wav2Vec2Config

# ì•ˆì „í•œ ëª¨ë¸ import
custom_Wav2Vec2ForEmotionClassification = None

def import_model_class():
    """ë‹¤ì–‘í•œ ê²½ë¡œì—ì„œ ëª¨ë¸ í´ë˜ìŠ¤ë¥¼ ì•ˆì „í•˜ê²Œ importí•©ë‹ˆë‹¤."""
    global custom_Wav2Vec2ForEmotionClassification
    
    import_attempts = [
        "model",
        "SER.Sagemaker.code.model", 
        "Sagemaker.code.model",
        "code.model",
    ]
    
    for module_name in import_attempts:
        try:
            logger.info(f"ğŸ” Attempting to import from: {module_name}")
            module = __import__(module_name, fromlist=['custom_Wav2Vec2ForEmotionClassification'])
            custom_Wav2Vec2ForEmotionClassification = getattr(module, 'custom_Wav2Vec2ForEmotionClassification')
            logger.info(f"âœ… Successfully imported from: {module_name}")
            return custom_Wav2Vec2ForEmotionClassification
        except (ImportError, AttributeError) as e:
            logger.warning(f"âŒ Failed to import from {module_name}: {e}")
            continue
    
    logger.error("âŒ Failed to import custom_Wav2Vec2ForEmotionClassification from any location")
    raise ImportError("Could not find custom_Wav2Vec2ForEmotionClassification in any known location")

# ëª¨ë¸ í´ë˜ìŠ¤ import ì‹¤í–‰
custom_Wav2Vec2ForEmotionClassification = import_model_class()

# ì „ì—­ ë³€ìˆ˜
model = None
processor = None
device = None
emotion_labels = ["Anxious", "Dry", "Kind", "Other"]
MODEL_SAMPLE_RATE = 16000  # ëª¨ë¸ì˜ ìƒ˜í”Œë§ ë ˆì´íŠ¸
MODEL_MAX_DURATION = 10.0
ROOT = Path(__file__).parent


def model_fn(model_dir: str):
    """
    SageMakerì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
    Args:
        model_dir: ëª¨ë¸ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ
    Returns:
        ë¡œë“œëœ ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
    """
    global device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model_dir = Path(model_dir)
    weight_dir = model_dir / "model" / "wav2vec"
    logger.info(f"Loading model from: {model_dir}")
    logger.info(f"Using device: {device}")
    
    try:    
        # ëª¨ë¸ ë¡œë“œ
        logger.info("Loading model...")
        
        model_config = Wav2Vec2Config.from_pretrained(
            "kresnik/wav2vec2-large-xlsr-korean",
            num_labels= 4,
            finetuning_task="emotion_classification"
        )
        
        model_config.num_speakers = 6
        model_config.char_vocab_size = 100

        model = custom_Wav2Vec2ForEmotionClassification.from_pretrained(
            weight_dir,
            config=model_config,
            ignore_mismatched_sizes=True
        )
        
        processor = Wav2Vec2Processor.from_pretrained(weight_dir)
        model.to(device)
        model.eval()
        
        logger.info("Model loaded successfully!")
        
        return {
            'model': model,
            'processor': processor,
            'device': device,
            'emotion_labels': emotion_labels
        }
        
    except Exception as e:
        logger.error(f"Error loading model: {str(e)}")
        raise

def input_fn(request_body: bytes, content_type: str) -> np.ndarray:
    """
    í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë°›ì€ ìš”ì²­ì„ ëª¨ë¸ì´ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” NumPy ë°°ì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    logger.info(f"Received request with content_type: {content_type}")
    try:
        if content_type == 'application/json':
            # 1. JSON íŒŒì‹± ë° Base64 ë°ì´í„° ì¶”ì¶œ
            data = json.loads(request_body)
            audio_base64 = data['instances'][0]['audio_data']
            
            # 2. Base64 ë””ì½”ë”©í•˜ì—¬ ë°”ì´íŠ¸ë¡œ ë³€í™˜
            audio_bytes = base64.b64decode(audio_base64)
            
            # 3. âœ… ë°”ì´íŠ¸ë¥¼ Raw PCMìœ¼ë¡œ ì§ì ‘ ì²˜ë¦¬ (sf.read ëŒ€ì‹  frombuffer ì‚¬ìš©)
            audio = np.frombuffer(audio_bytes, dtype=np.int16)
            audio = audio.astype(np.float32) / 32768.0 # float32ë¡œ ì •ê·œí™”
            sr = MODEL_SAMPLE_RATE # Raw PCMì´ë¯€ë¡œ ìƒ˜í”Œë§ ë ˆì´íŠ¸ë¥¼ ì§ì ‘ ì§€ì •

        elif content_type == 'audio/wav':
            audio_bytes = request_body
            audio, sr = sf.read(BytesIO(audio_bytes))
            
        elif content_type == 'application/octet-stream':
            audio_bytes = request_body
            audio = np.frombuffer(audio_bytes, dtype=np.int16)
            audio = audio.astype(np.float32) / 32768.0 # float32ë¡œ ì •ê·œí™”
            sr = MODEL_SAMPLE_RATE 
            
        else:
            raise ValueError(f"Unsupported content type: {content_type}")

        # --- ê³µí†µ í›„ì²˜ë¦¬ ë¡œì§ ---
        if audio.ndim > 1: audio = np.mean(audio, axis=1) # ìŠ¤í…Œë ˆì˜¤ -> ëª¨ë…¸
        if sr != MODEL_SAMPLE_RATE:
            logger.info(f"Resampling from {sr} Hz to {MODEL_SAMPLE_RATE} Hz")
            audio = librosa.resample(y=audio, orig_sr=sr, target_sr=MODEL_SAMPLE_RATE)
        if np.max(np.abs(audio)) > 0: audio = audio / np.max(np.abs(audio)) # ì •ê·œí™”

        logger.info(f"Decoded audio array with shape: {audio.shape}")
        return audio.astype(np.float32)
        
    except Exception as e:
        logger.error(f"ERROR in input_fn: {e}")
        raise ValueError(f"Failed to process input audio: {e}")

def predict_fn(input_data: np.ndarray, model_pack: dict) -> dict:
    """
    ì „ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ ë°°ì—´ì„ ë°›ì•„ ëª¨ë¸ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ê³ , ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    model = model_pack['model']
    processor = model_pack['processor']
    device = model_pack['device']
    emotion_labels = model_pack['emotion_labels']
    audio = input_data
    
    target_length = int(MODEL_SAMPLE_RATE * MODEL_MAX_DURATION)
    if len(audio) > target_length:
        start_idx = (len(audio) - target_length) // 2
        audio = audio[start_idx : start_idx + target_length]
    elif len(audio) < target_length:
        pad_length = target_length - len(audio)
        audio = np.pad(audio, (0, pad_length), mode='constant')
        
    inputs = processor(audio, sampling_rate=MODEL_SAMPLE_RATE, return_tensors="pt")
    input_values = inputs.input_values.to(device)
    
    try:
        with torch.no_grad():
            outputs = model(input_values)
            logits = outputs.get('emotion_logits')
            if logits is None:
                raise ValueError("Model output dictionary does not contain 'emotion_logits' key")

            probabilities = torch.softmax(logits, dim=-1).squeeze()
            predicted_idx = torch.argmax(probabilities).item()
            probabilities_np = probabilities.cpu().numpy()

        # 4. ê²°ê³¼ í¬ë§·íŒ…
        results = {
            'predicted_emotion': emotion_labels[predicted_idx],
            'confidence': float(probabilities_np[predicted_idx]),
            'emotion_scores': {label: float(prob) for label, prob in zip(emotion_labels, probabilities_np)}
        }
        print(f"Prediction successful: {results['emotion_scores']}")
        return results

    except Exception as e:
        print(f"ERROR during prediction: {e}")
        return {'error': str(e)}


def output_fn(prediction: dict, accept: str) -> bytes:
    """
    ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í´ë¼ì´ì–¸íŠ¸ê°€ ìš”ì²­í•œ í˜•ì‹(JSON)ìœ¼ë¡œ ì¸ì½”ë”©í•©ë‹ˆë‹¤.
    """
    if accept != 'application/json':
        raise ValueError(f"Unsupported accept type: {accept}")

    # bytes ê°ì²´ë§Œ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •
    return json.dumps(prediction, ensure_ascii=False).encode('utf-8')

# SageMaker ë¹„ë™ê¸° ì¶”ë¡ ì„ ìœ„í•œ ì¶”ê°€ í•¨ìˆ˜ë“¤
def health_check():
    """í—¬ìŠ¤ ì²´í¬ í•¨ìˆ˜"""
    return {"status": "healthy", "model_loaded": model is not None}


def batch_predict(batch_input: List[Dict[str, Any]], model_dict: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    ë°°ì¹˜ ì˜ˆì¸¡ í•¨ìˆ˜ (ì—¬ëŸ¬ ì˜¤ë””ì˜¤ íŒŒì¼ ë™ì‹œ ì²˜ë¦¬)
    
    Args:
        batch_input: ë°°ì¹˜ ì…ë ¥ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        model_dict: ëª¨ë¸ ë”•ì…”ë„ˆë¦¬
        
    Returns:
        ë°°ì¹˜ ì˜ˆì¸¡ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    results = []
    for input_data in batch_input:
        result = predict_fn(input_data, model_dict)
        results.append(result)
    return results


# SageMaker Inference Containerë¥¼ ìœ„í•œ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
if __name__ == "__main__":
    import sys
    
    # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
    if len(sys.argv) > 1 and sys.argv[1] == "test":
        print("Testing SageMaker inference...")
        
        # ë”ë¯¸ ëª¨ë¸ ë¡œë“œ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” SageMakerê°€ í˜¸ì¶œ)
        model_dir = ROOT / "pre_trained" / "Wav2Vec2_Adversary" # SageMaker ê¸°ë³¸ ëª¨ë¸ ê²½ë¡œ
            
        if os.path.exists(model_dir):
            model_dict = model_fn(model_dir)
            print("Model loaded successfully!")
            
            # ë”ë¯¸ ì˜¤ë””ì˜¤ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
            dummy_audio = np.random.randn(16000).astype(np.float32)  # 1ì´ˆ ë”ë¯¸ ì˜¤ë””ì˜¤
            
            # ì˜¤ë””ì˜¤ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜
            with BytesIO() as buf:
                sf.write(buf, dummy_audio, 16000, format='WAV')
                audio_bytes = buf.getvalue()
            
            # ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
            input_data = {'audio_data': audio_bytes, 'format': 'binary'}
            result = predict_fn(input_data, model_dict)
            print(f"Test prediction result: {result}")
        else:
            print(f"Model directory not found: {model_dir}")
    else:
        print("SageMaker inference server ready!")
