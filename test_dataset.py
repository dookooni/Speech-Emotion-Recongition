#!/usr/bin/env python3
"""
Large ë°ì´í„°ì…‹ì— ëŒ€í•œ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
í•™ìŠµëœ ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ Classification Reportë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import os
import torch
import numpy as np
from pathlib import Path
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
from tqdm import tqdm
import argparse
import json
import warnings
warnings.filterwarnings('ignore')
import json

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ import
from config import Config
from data_utils import (
    build_large_corpus_index, 
    split_large_dataset, 
    EMOTION_LABELS
)
from torch.utils.data import DataLoader
from datasets import collate_fn, EmotionDataset
from data_utils import balance_by_undersampling_majority
from Wav2Vec2_seq_clf import custom_Wav2Vec2ForEmotionClassification, custom_Wav2Vec2ForEmotionClassification_Text
from transformers import Wav2Vec2Config, Wav2Vec2Processor


def load_model_and_processor(checkpoint_path: str, config: Config, device: torch.device, num_speakers: int = 500):
    """
    í•™ìŠµëœ ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œ ë¡œë“œ - create_model_and_processor ê¸°ë°˜
    - Hugging Face safetensors (.safetensors)
    - PyTorch checkpoint (.pth, .pt)
    - Hugging Face ëª¨ë¸ ë””ë ‰í† ë¦¬
    """
    print(f"ğŸ“‚ ëª¨ë¸ ë¡œë“œ ì¤‘: {checkpoint_path}")
    
    # ì„¤ì • ìˆ˜ì •
    model_config = Wav2Vec2Config.from_pretrained(
        config.model.model_name,
        num_labels=config.model.num_labels,
        label2id=config.model.label2id,
        id2label=config.model.id2label,
        finetuning_task="emotion_classification"
    )
    model_config.num_speakers = num_speakers  # í™”ì ìˆ˜ ì„¤ì •
    
    if config.char_vocab:
        model_config.char_vocab_size = len(config.char_vocab)
    
    # ëª¨ë¸ ì´ˆê¸°í™” (ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ì—†ì´)
    model = custom_Wav2Vec2ForEmotionClassification.from_pretrained(
        config.model.model_name,
        config=model_config,
        ignore_mismatched_sizes=True
    )
    
    # í”„ë¡œì„¸ì„œ ë¡œë“œ
    processor = Wav2Vec2Processor.from_pretrained(config.model.model_name)
    
    # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
    model = model.to(device)
    
    # ì²´í¬í¬ì¸íŠ¸ê°€ ì œê³µëœ ê²½ìš° ê°€ì¤‘ì¹˜ ë¡œë“œ
    if checkpoint_path and os.path.exists(checkpoint_path):
        # ê²½ë¡œê°€ ë””ë ‰í† ë¦¬ì¸ì§€ íŒŒì¼ì¸ì§€ í™•ì¸
        if os.path.isdir(checkpoint_path):
            # Hugging Face ëª¨ë¸ ë””ë ‰í† ë¦¬ì¸ ê²½ìš°
            try:
                print("ğŸ¤— Hugging Face ëª¨ë¸ ë””ë ‰í† ë¦¬ì—ì„œ ê°€ì¤‘ì¹˜ ë¡œë“œ ì¤‘...")
                
                # ìƒˆë¡œìš´ ëª¨ë¸ì„ í•´ë‹¹ ë””ë ‰í† ë¦¬ì—ì„œ ë¡œë“œ
                loaded_model = custom_Wav2Vec2ForEmotionClassification.from_pretrained(
                    checkpoint_path,
                    config=model_config,
                    ignore_mismatched_sizes=True,
                    local_files_only=True
                )
                
                model = loaded_model.to(device)
                print("âœ… Hugging Face ëª¨ë¸ ë””ë ‰í† ë¦¬ì—ì„œ ë¡œë“œ ì™„ë£Œ")
                
            except Exception as e:
                print(f"âŒ Hugging Face ë””ë ‰í† ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
                print("ğŸ”„ ê¸°ë³¸ ê°€ì¤‘ì¹˜ë¡œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
                
        elif checkpoint_path.endswith('.safetensors'):
            # safetensors íŒŒì¼ì¸ ê²½ìš°
            try:
                from safetensors.torch import load_file
                print("ğŸ”’ SafeTensors íŒŒì¼ì—ì„œ ë¡œë“œ ì¤‘...")
                
                state_dict = load_file(checkpoint_path, device=str(device))
                
                # í‚¤ ì´ë¦„ í™•ì¸ ë° ë§¤í•‘
                if any(key.startswith('wav2vec2.') for key in state_dict.keys()):
                    # ì´ë¯¸ ì˜¬ë°”ë¥¸ í‚¤ êµ¬ì¡°ì¸ ê²½ìš°
                    missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)
                else:
                    # í‚¤ êµ¬ì¡° ë³€ê²½ì´ í•„ìš”í•œ ê²½ìš°
                    mapped_state_dict = {}
                    for key, value in state_dict.items():
                        if key.startswith('model.'):
                            new_key = key.replace('model.', '')
                            mapped_state_dict[new_key] = value
                        else:
                            mapped_state_dict[key] = value
                    missing_keys, unexpected_keys = model.load_state_dict(mapped_state_dict, strict=False)
                
                if missing_keys:
                    print(f"âš ï¸  ëˆ„ë½ëœ í‚¤: {missing_keys[:5]}{'...' if len(missing_keys) > 5 else ''}")
                if unexpected_keys:
                    print(f"âš ï¸  ì˜ˆìƒì¹˜ ëª»í•œ í‚¤: {unexpected_keys[:5]}{'...' if len(unexpected_keys) > 5 else ''}")
                    
                print("âœ… SafeTensors íŒŒì¼ì—ì„œ ë¡œë“œ ì™„ë£Œ")
                
            except ImportError:
                print("âŒ safetensors ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install safetensors")
                print("ğŸ”„ ê¸°ë³¸ ê°€ì¤‘ì¹˜ë¡œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
            except Exception as e:
                print(f"âŒ SafeTensors ë¡œë“œ ì‹¤íŒ¨: {e}")
                print("ğŸ”„ ê¸°ë³¸ ê°€ì¤‘ì¹˜ë¡œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
                
        else:
            # PyTorch ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì¸ ê²½ìš° (.pth, .pt)
            try:
                print("âš¡ PyTorch ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë¡œë“œ ì¤‘...")
                checkpoint = torch.load(checkpoint_path, map_location=device)
                
                # ë‹¤ì–‘í•œ ì²´í¬í¬ì¸íŠ¸ í˜•ì‹ ì§€ì›
                if 'model_state_dict' in checkpoint:
                    state_dict = checkpoint['model_state_dict']
                    epoch_info = checkpoint.get('epoch', 'unknown')
                    print(f"ğŸ“Š ì²´í¬í¬ì¸íŠ¸ ì •ë³´: epoch {epoch_info}")
                elif 'state_dict' in checkpoint:
                    state_dict = checkpoint['state_dict']
                elif isinstance(checkpoint, dict) and any('wav2vec2' in key for key in checkpoint.keys()):
                    # ì§ì ‘ state_dictì¸ ê²½ìš°
                    state_dict = checkpoint
                else:
                    print("âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì²´í¬í¬ì¸íŠ¸ í˜•ì‹ì…ë‹ˆë‹¤.")
                    print(f"ì‚¬ìš© ê°€ëŠ¥í•œ í‚¤: {list(checkpoint.keys()) if isinstance(checkpoint, dict) else 'dictê°€ ì•„ë‹˜'}")
                    print("ğŸ”„ ê¸°ë³¸ ê°€ì¤‘ì¹˜ë¡œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
                    state_dict = None
                
                if state_dict is not None:
                    # í‚¤ ì´ë¦„ ë§¤í•‘ (í•„ìš”ì‹œ)
                    mapped_state_dict = {}
                    for key, value in state_dict.items():
                        if key.startswith('module.'):  # DataParallel ì‚¬ìš© ì‹œ
                            new_key = key.replace('module.', '')
                            mapped_state_dict[new_key] = value
                        else:
                            mapped_state_dict[key] = value
                    
                    # ëª¨ë¸ì— ë¡œë“œ
                    missing_keys, unexpected_keys = model.load_state_dict(mapped_state_dict, strict=False)
                    
                    if missing_keys:
                        print(f"âš ï¸  ëˆ„ë½ëœ í‚¤: {missing_keys[:5]}{'...' if len(missing_keys) > 5 else ''}")
                    if unexpected_keys:
                        print(f"âš ï¸  ì˜ˆìƒì¹˜ ëª»í•œ í‚¤: {unexpected_keys[:5]}{'...' if len(unexpected_keys) > 5 else ''}")
                        
                    print("âœ… PyTorch ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë¡œë“œ ì™„ë£Œ")
                
            except Exception as e:
                print(f"âŒ PyTorch ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                print("ğŸ”„ ê¸°ë³¸ ê°€ì¤‘ì¹˜ë¡œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
    else:
        print("ğŸ“¦ ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    model.eval()
    print(f"ğŸ“± ëª¨ë¸ì´ {device}ì— ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    return model, processor


def evaluate_model(model, test_loader, device, emotion_labels):
    """ëª¨ë¸ í‰ê°€ ë° ì˜ˆì¸¡ ê²°ê³¼ ìˆ˜ì§‘"""
    model.eval()
    all_predictions = []
    all_true_labels = []
    all_probabilities = []
    
    print("ğŸ” ëª¨ë¸ í‰ê°€ ì¤‘...")
    
    with torch.no_grad():
        for batch in tqdm(test_loader, desc="Testing"):
            # ë°°ì¹˜ ë°ì´í„°ë¥¼ deviceë¡œ ì´ë™
            input_values = batch['input_values'].to(device)
            labels = batch['labels'].to(device)
            
            # ëª¨ë¸ ì˜ˆì¸¡
            outputs = model(input_values)
            # logits = outputs.logits if hasattr(outputs, 'logits') else outputs
            logits = outputs.get("emotion_logits")
            
            # ì˜ˆì¸¡ ê²°ê³¼ ìˆ˜ì§‘
            probabilities = torch.softmax(logits, dim=-1)
            predictions = torch.argmax(logits, dim=-1)
            
            all_predictions.extend(predictions.cpu().numpy())
            all_true_labels.extend(labels.cpu().numpy())
            all_probabilities.extend(probabilities.cpu().numpy())
    
    return np.array(all_predictions), np.array(all_true_labels), np.array(all_probabilities)


def generate_classification_report(y_true, y_pred, emotion_labels, save_dir=None):
    """Classification Report ìƒì„± ë° ì €ì¥"""
    
    # Classification Report ìƒì„±
    report = classification_report(
        y_true, 
        y_pred, 
        target_names=emotion_labels,
        digits=4,
        output_dict=True
    )
    
    # í…ìŠ¤íŠ¸ í˜•íƒœ ë¦¬í¬íŠ¸
    text_report = classification_report(
        y_true, 
        y_pred, 
        target_names=emotion_labels,
        digits=4
    )
    
    print("ğŸ“Š Classification Report:")
    print("=" * 60)
    print(text_report)
    print("=" * 60)
    
    # ì €ì¥
    if save_dir:
        os.makedirs(save_dir, exist_ok=True)
        
        # JSON í˜•íƒœë¡œ ì €ì¥
        with open(os.path.join(save_dir, 'classification_report.json'), 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ì €ì¥
        with open(os.path.join(save_dir, 'classification_report.txt'), 'w', encoding='utf-8') as f:
            f.write(text_report)
        
        print(f"ğŸ’¾ Classification Report ì €ì¥ ì™„ë£Œ: {save_dir}")
    
    return report

def plot_confusion_matrix(y_true, y_pred, emotion_labels, save_dir=None):
    """Confusion Matrix ì‹œê°í™”"""
    cm = confusion_matrix(y_true, y_pred)
    
    plt.figure(figsize=(10, 8))
    sns.heatmap(
        cm, 
        annot=True, 
        fmt='d', 
        cmap='Blues',
        xticklabels=emotion_labels,
        yticklabels=emotion_labels
    )
    plt.title('Confusion Matrix - Large Dataset Test')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    
    if save_dir:
        plt.savefig(os.path.join(save_dir, 'confusion_matrix.png'), dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ Confusion Matrix ì €ì¥ ì™„ë£Œ: {save_dir}/confusion_matrix.png")
    
    plt.show()
    
    return cm


def main():
    parser = argparse.ArgumentParser(description='Large ë°ì´í„°ì…‹ ëª¨ë¸ í…ŒìŠ¤íŠ¸')
    parser.add_argument('--checkpoint', type=str, 
                       help='ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ (ì—†ìœ¼ë©´ ë°ì´í„°ë§Œ í™•ì¸)')
    parser.add_argument('--config', type=str, default='config.py',
                       help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--output_dir', type=str, default='./test_results',
                       help='ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--batch_size', type=int, default=32,
                       help='ë°°ì¹˜ í¬ê¸°')
    parser.add_argument('--data_only', action='store_true',
                       help='ë°ì´í„° ë¡œë“œ í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰')
    
    args = parser.parse_args()
    
    # ì„¤ì • ë¡œë“œ
    config = Config()
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ”§ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    
    # Large ë°ì´í„°ì…‹ ë¡œë“œ
    print("ğŸ“Š Large ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...")
    large_index = build_large_corpus_index(
        str(config.paths.large_data_dir), 
        with_sentence=True
    )
    index = balance_by_undersampling_majority(large_index)
    if not large_index:
        print("âŒ Large ë°ì´í„°ì…‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë°ì´í„° ë¶„í•  (í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë§Œ í•„ìš”)
    print("ğŸ”„ ë°ì´í„° ë¶„í•  ì¤‘...")
    (train_paths, train_labels, train_sentences), \
    (val_paths, val_labels, val_sentences), \
    (test_paths, test_labels, test_sentences) = split_large_dataset(
        index,
        val_speaker_ratio=0.2,
        test_speaker_ratio=0.2,
        val_content_ratio=0.2,
        test_content_ratio=0.2,
        with_sentence=True
    )
    
    print(f"ğŸ“‹ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_paths)}ê°œ ìƒ˜í”Œ")
    
    # ë°ì´í„°ë§Œ í™•ì¸í•˜ê³  ì¢…ë£Œ
    if args.data_only or not args.checkpoint:
        print("âœ… ë°ì´í„° ë¡œë“œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("ğŸ’¡ ëª¨ë¸ í…ŒìŠ¤íŠ¸ë¥¼ ì›í•˜ë©´ --checkpoint ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        return
    
    # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(args.checkpoint):
        print(f"âŒ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.checkpoint}")
        return
    
    # ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œ ë¡œë“œ
    model, processor = load_model_and_processor(args.checkpoint, config, device)
    
    if model is None:
        print("âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
        return
    
    # ë°ì´í„°ì…‹ ìƒì„±
    test_dataset = EmotionDataset(test_paths, test_labels, processor, is_training=False)

    # ë°ì´í„° ë¡œë” ìƒì„±
    test_loader = DataLoader(
        test_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        collate_fn=collate_fn,
        drop_last=False,
    )
    
    # ëª¨ë¸ í‰ê°€
    y_pred, y_true, probabilities = evaluate_model(model, test_loader, device, EMOTION_LABELS)
    
    # Classification Report ìƒì„±
    report = generate_classification_report(y_true, y_pred, EMOTION_LABELS, args.output_dir)
    
    # Confusion Matrix ìƒì„±
    cm = plot_confusion_matrix(y_true, y_pred, EMOTION_LABELS, args.output_dir)
    
    # ì¶”ê°€ í†µê³„ ì •ë³´
    print("\nğŸ“ˆ ì¶”ê°€ í†µê³„ ì •ë³´:")
    print(f"ì „ì²´ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {len(y_true)}")
    print(f"ì •í™•ë„: {(y_pred == y_true).sum() / len(y_true):.4f}")
    print(f"report : {report}")
    print(f"confusion matrix : {cm}")
    
    # í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜
    from collections import Counter
    true_counts = Counter(y_true)
    pred_counts = Counter(y_pred)
    
    print("\nğŸ“Š í´ë˜ìŠ¤ë³„ ë¶„í¬:")
    for i, emotion in enumerate(EMOTION_LABELS):
        print(f"{emotion}: ì‹¤ì œ {true_counts[i]}, ì˜ˆì¸¡ {pred_counts[i]}")
    
    print(f"\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ê²°ê³¼ëŠ” {args.output_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()
