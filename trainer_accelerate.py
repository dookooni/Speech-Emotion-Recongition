import torch
import torch.nn as nn
import torch.optim as optim
from transformers import Wav2Vec2Processor, Wav2Vec2Config
from accelerate import Accelerator, DistributedDataParallelKwargs
from torch.utils.data import DataLoader
import warnings
warnings.filterwarnings('ignore')

from config import config
from datasets import EmotionDataset, collate_fn, preprocess_audio
from utils import setup_logging, CheckpointManager, validate_audio_files
from data_utils import (split_speaker_and_content, build_corpus_index, extract_speaker_id, extract_number_from_filename,
                       build_large_corpus_index, balance_large_dataset, split_large_dataset, balance_by_undersampling_majority)
from Wav2Vec2_seq_clf import custom_Wav2Vec2ForEmotionClassification, HybridEmotionModel
from model_utils import enable_last_k_blocks, enable_hybrid_last_k_blocks

from collections import Counter
from tqdm import tqdm
from sklearn.metrics import classification_report, accuracy_score, f1_score

import wandb
import random
import os

def create_model_and_processor(freeze_base_model: bool = True, num_speakers: int = 500):
    """ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œ ìƒì„±"""
    print(f"ğŸ¤– ëª¨ë¸ ë¡œë”©: {config.model.model_name}")
    
    # ì„¤ì • ìˆ˜ì •
    model_config = Wav2Vec2Config.from_pretrained(
        config.model.model_name,
        num_labels=config.model.num_labels,
        label2id=config.model.label2id,
        id2label=config.model.id2label,
        finetuning_task="emotion_classification"
    )
    model_config.num_speakers = num_speakers  # í™”ì ìˆ˜ ì„¤ì •
    
    if config.char_vocab:
        model_config.char_vocab_size = len(config.char_vocab)
    
    model = custom_Wav2Vec2ForEmotionClassification.from_pretrained(
        config.model.model_name,
        config=model_config,
        ignore_mismatched_sizes=True
    )
    
    processor = Wav2Vec2Processor.from_pretrained(config.model.model_name)
    
    if freeze_base_model:
        for param in model.wav2vec2.parameters():
            param.requires_grad = False
        print("âœ… Base model íŒŒë¼ë¯¸í„° ê³ ì •")
    
    return model, processor

def create_hybrid_model_and_processor(config, freeze_w2v2_base: bool = True):
    """í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ê³¼ Wav2Vec2 í”„ë¡œì„¸ì„œë¥¼ ìƒì„±"""
    
    w2v2_model_name = config.model.w2v2_model_name
    prosody_model_name = config.model.prosody_model_name
    num_labels = config.model.num_labels
    
    print(f"ğŸ¤– ë‚´ìš© ì „ë¬¸ê°€ ë¡œë”©: {w2v2_model_name}")
    print(f"ğŸ¶ í”„ë¡œì†Œë”” ì „ë¬¸ê°€ ë¡œë”©: {prosody_model_name}")
    
    # 1. Wav2Vec2 í”„ë¡œì„¸ì„œ ë¡œë”© (ë°ì´í„° ì „ì²˜ë¦¬ì— ì‚¬ìš©)
    processor = Wav2Vec2Processor.from_pretrained(w2v2_model_name)
    
    # 2. í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    model = HybridEmotionModel(
        w2v2_model_name=w2v2_model_name,
        prosody_model_name=prosody_model_name,
        num_labels=num_labels,
        freeze_w2v2=freeze_w2v2_base,
        freeze_prosody=True  # í”„ë¡œì†Œë”” ëª¨ë¸ì€ í•­ìƒ ë™ê²°í•˜ëŠ” ê²ƒì„ ì¶”ì²œ
    )
    
    if freeze_w2v2_base:
        print("âœ… ë‚´ìš© ì „ë¬¸ê°€(Wav2Vec2) Base model íŒŒë¼ë¯¸í„° ê³ ì •")
    print("âœ… í”„ë¡œì†Œë”” ì „ë¬¸ê°€(Speechbrain) íŒŒë¼ë¯¸í„° ê³ ì •")
    
    return model, processor

def train_model_accelerate(accelerator, model, train_loader, val_loader, num_epochs=3, learning_rate=3e-5):
    """Acceleratorë¥¼ ì‚¬ìš©í•œ ë³‘ë ¬ í›ˆë ¨ ë£¨í”„"""
    
    if accelerator.is_main_process:
        print("ğŸš€ ì˜µí‹°ë§ˆì´ì € ì„¤ì • (ì°¨ë“± í•™ìŠµë¥  ì ìš©)")
    
    backbone_params = []
    head_params = []

    for n, p in model.named_parameters():
        if not p.requires_grad:
            continue
        if n.startswith("wav2vec2."):
            backbone_params.append(p)
        else:
            # pooler, stats_projector, projector(ë¶€ëª¨), classifier, adversaries ë“±
            head_params.append(p)

    optimizer = optim.AdamW([
        {"params": backbone_params, "lr": 5e-6, "weight_decay": 0.01},
        {"params": head_params, "lr": 5e-5, "weight_decay": 0.01},
    ])
    
    # ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
    total_steps = len(train_loader) * num_epochs
    accumulation_steps = 8
    scheduler_steps = total_steps // accumulation_steps
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=scheduler_steps)
    
    best_f1 = 0
    best_model_state = None
    
    if accelerator.is_main_process:
        print(f"\nğŸš€ í›ˆë ¨ ì‹œì‘!")
        print(f"   ì´ ì—í¬í¬: {num_epochs}")
        print(f"   ë°°ì¹˜ ìˆ˜: {len(train_loader)}")
        print(f"   ì´ ìŠ¤í…: {total_steps}")
        print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ GPU: {accelerator.num_processes}")
    
    # Speaker ì ëŒ€ì lambda ë° warmup ì„¤ì •
    max_adv = 0.75
    warmup_epochs = 2.0
    # ê°€ì¤‘ì¹˜ ì¡°ì • (Anxious, Dry, Kind, Other ìˆœì„œ)
    class_weights = torch.tensor([1.0, 1.0, 0.5, 0.5]).to(accelerator.device)

    for epoch in range(num_epochs):
        if accelerator.is_main_process:
            print(f"\n=== Epoch {epoch + 1}/{num_epochs} ===")
        
        model.train()
        train_loss = 0
        train_predictions = []
        train_true_labels = []
        optimizer.zero_grad()

        if accelerator.is_main_process:
            progress_bar = tqdm(train_loader, desc=f"Epoch {epoch+1} Training")
        else:
            progress_bar = train_loader

        for step, batch in enumerate(progress_bar):
            current_step = epoch * len(train_loader) + step
            total_warmup_steps = warmup_epochs * len(train_loader)
            progress = min(1.0, current_step / total_warmup_steps)
            current_adv_lambda = max_adv * progress
            # current_adv_lambda = 0.0 
            
            outputs = model(
                input_values=batch['input_values'],
                attention_mask=batch['attention_mask'],
                labels=batch['labels'],
                adv_lambda=current_adv_lambda,
                speaker_ids=batch['speaker_ids'],
                class_weights=class_weights,
            )
            
            loss = outputs['loss']
            if loss is None or torch.isnan(loss) or torch.isinf(loss):
                continue

            loss /= accumulation_steps
            accelerator.backward(loss)  

            if (step + 1) % accumulation_steps == 0:
                accelerator.clip_grad_norm_(model.parameters(), 1.0)  
                optimizer.step()
                scheduler.step()
                optimizer.zero_grad()
            
            train_loss += loss.item()
            
            preds = torch.argmax(outputs['emotion_logits'], dim=-1)
            
            all_preds = accelerator.gather(preds)
            all_labels = accelerator.gather(batch['labels'])
            
            if accelerator.is_main_process:
                train_predictions.extend(all_preds.cpu().numpy())
                train_true_labels.extend(all_labels.cpu().numpy())
                
                if hasattr(progress_bar, 'set_postfix'):
                    progress_bar.set_postfix({
                        'loss': f'{loss.item():.4f}',
                        'lr': f'{scheduler.get_last_lr()[0]:.6f}'
                    })
        
        train_loss /= len(train_loader)
        
        if accelerator.is_main_process:
            train_accuracy = accuracy_score(train_true_labels, train_predictions)
            train_f1 = f1_score(train_true_labels, train_predictions, average='weighted')

            # Weight & Biases ë¡œê¹…
            wandb.log({
                "epoch": epoch,
                "train/loss": train_loss,
                "train/accuracy": train_accuracy,
                "train/f1": train_f1
            })

        accelerator.wait_for_everyone() 
        if accelerator.is_main_process:
            print("ğŸ“Š ê²€ì¦ ì¤‘...")
        
        val_results = evaluate_model_accelerate(accelerator, model, val_loader, epoch=epoch, is_training=True)
        
        if accelerator.is_main_process:
            print(f"ğŸ” ê²€ì¦ ê²°ê³¼ - Loss: {val_results['loss']:.4f}, Acc: {val_results['accuracy']:.4f}, F1: {val_results['f1']:.4f}")
            
            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
            if val_results['f1'] > best_f1:
                best_f1 = val_results['f1']
                best_model_state = accelerator.get_state_dict(model)
                print(f"âœ¨ ìƒˆë¡œìš´ ìµœê³  F1 ì ìˆ˜: {best_f1:.4f}")
        
        print(f"\nğŸ’« ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (F1: {best_f1:.4f})")
    
    return best_model_state

def evaluate_model_accelerate(accelerator, model, dataloader, epoch=None, is_training=False):
    """Acceleratorë¥¼ ì‚¬ìš©í•œ ëª¨ë¸ í‰ê°€"""
    model.eval()
    all_losses = []
    all_predictions = []
    all_true_labels = []

    with torch.no_grad():            
        for eval_step, batch in enumerate(dataloader):
   
            outputs = model(
                input_values=batch['input_values'],
                attention_mask=batch['attention_mask'],
                labels=batch['labels'],
                content_labels=batch['content_labels'],
                content_labels_lengths=batch['content_labels_lengths'],
                adv_lambda=0.0,  # í‰ê°€ ì‹œì—ëŠ” ì ëŒ€ì  ì†ì‹¤ ë°˜ì˜ ì•ˆí•¨
                speaker_ids=None,
            )

            loss = outputs['loss']
            
            if loss is None:
                loss_fct = nn.CrossEntropyLoss()
                unwrapped_model = accelerator.unwrap_model(model)
                loss = loss_fct(outputs['emotion_logits'].view(-1, unwrapped_model.config.num_labels), 
                               batch['labels'].view(-1))
            
            preds = torch.argmax(outputs['emotion_logits'], dim=-1)
            labels = batch['labels']
            
            gathered_losses = accelerator.gather_for_metrics(loss)
            gathered_preds = accelerator.gather_for_metrics(preds)
            gathered_labels = accelerator.gather_for_metrics(labels)
            
            all_losses.extend(gathered_losses.cpu().numpy())
            all_predictions.extend(gathered_preds.cpu().numpy())
            all_true_labels.extend(gathered_labels.cpu().numpy())
    
    if accelerator.is_main_process:
        avg_loss = sum(all_losses) / len(all_losses) if all_losses else 0
        accuracy = accuracy_score(all_true_labels, all_predictions)
        f1 = f1_score(all_true_labels, all_predictions, average='weighted')

        if is_training:
            wandb.log({
                "epoch": epoch,
                "val/loss": avg_loss,
                "val/accuracy": accuracy,
                "val/f1": f1,
            })
        
        return {
            'loss': avg_loss,
            'accuracy': accuracy,
            'f1': f1,
            'predictions': all_predictions,
            'true_labels': all_true_labels
        }
    else:
        # ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ëŠ” ë¹ˆ ê²°ê³¼ ë°˜í™˜
        return {
            'loss': 0.0,
            'accuracy': 0.0,
            'f1': 0.0,
            'predictions': [],
            'true_labels': []
        }

def main():
    """ë©”ì¸ í›ˆë ¨ í•¨ìˆ˜ - Accelerator ì‚¬ìš©"""
    try:
        # ì‹œë“œ ì„¤ì • (ì•ˆí•  ì‹œ, í”„ë¡œì„¸ì„œ ë‹¹ ë°°ì¹˜ í¬ê¸° ì˜í•œ ë¶ˆì•ˆì •ì„± ë°œìƒ ê°€ëŠ¥)
        seed = 42 
        random.seed(seed)
        torch.manual_seed(seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(seed)

        # Accelerator ì´ˆê¸°í™”
        ddp_kwargs = DistributedDataParallelKwargs(find_unused_parameters=True)
        accelerator = Accelerator(
            gradient_accumulation_steps=8,
            mixed_precision='fp16',  # fp16
            kwargs_handlers=[ddp_kwargs]
        )

        local_rank = int(os.environ.get("LOCAL_RANK", 0))
        gpu_id = torch.cuda.current_device()
        pid = os.getpid()
        with accelerator.main_process_first():
            print(f"ğŸš€ [Process ID: {pid}] Rank: {local_rank} is running on GPU: {gpu_id}")

        # ë¡œê¹…ì€ main processì—ì„œë§Œ
        if accelerator.is_main_process:
            logger = setup_logging("INFO", "training_accelerate.log")
            logger.info("ğŸš€ SER ëª¨ë¸ í›ˆë ¨ ì‹œì‘ (Accelerator ì‚¬ìš©)")
            
            logger.info(f"ëª¨ë¸: {config.model.model_name}")
            logger.info(f"ê°ì • ë¼ë²¨: {config.model.emotion_labels}")
            logger.info(f"ë°°ì¹˜ í¬ê¸°: {config.training.batch_size}")
            logger.info(f"í•™ìŠµë¥ : {config.training.learning_rate}")
            logger.info(f"ì‚¬ìš© ì¥ì¹˜: {accelerator.device}")
            logger.info(f"GPU í”„ë¡œì„¸ìŠ¤ ìˆ˜: {accelerator.num_processes}")

            # Weight & Biases ì´ˆê¸°í™”
            wandb.init(
                project="Speech_Emotion_Recognition",
                name="adv lambda 0.75 (spk id normal) 20 epoch last 15 Adversary 4 Class Classification Large Dataset Balancing (Multi-GPU) class_weight label_smoothing 0.1",
                config={
                    "learning_rate": config.training.learning_rate,
                    "epochs": config.training.num_epochs,
                    "batch_size": config.training.batch_size,
                    "architecture": "custom_Wav2Vec2ForEmotionClassification",
                    "num_gpus": accelerator.num_processes,
                }
            )

        # ë°ì´í„° ë¡œë“œ (Small vs Large ë°ì´í„°ì…‹ ì„ íƒ)
        if config.data.use_large_dataset:
            if accelerator.is_main_process:
                print("ğŸ“Š Large ë°ì´í„°ì…‹ ì‚¬ìš© ì¤‘...")
                print(f"ğŸ“ Large ë°ì´í„° ê²½ë¡œ: {config.paths.large_data_dir}")
            
            # Large ë°ì´í„°ì…‹ ì¸ë±ìŠ¤ ìƒì„±
            large_index = build_large_corpus_index(str(config.paths.large_data_dir))
            if not large_index:
                if accelerator.is_main_process:
                    print("âŒ Large ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨. Small ë°ì´í„°ì…‹ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                config.data.use_large_dataset = False
            else:
                # í´ë˜ìŠ¤ ê· í˜• ì¡°ì •
                if accelerator.is_main_process:
                    print(f"âš–ï¸ í´ë˜ìŠ¤ ê· í˜• ì¡°ì • ì¤‘ (ë¹„ìœ¨: {config.data.large_balance_ratio})")
                index = balance_by_undersampling_majority(large_index)
                if accelerator.is_main_process:
                    print(f"âœ… ê· í˜• ì¡°ì • ì™„ë£Œ - ìµœì¢… ìƒ˜í”Œ ìˆ˜: {len(index)}ê°œ")
        
        if not config.data.use_large_dataset:
            if accelerator.is_main_process:
                print("ğŸ“Š Small ë°ì´í„°ì…‹ ì‚¬ìš© ì¤‘ (í´ë˜ìŠ¤ ê· í˜• ë§ì¶”ê¸°)...")
            
            # ë¨¼ì € ì „ì²´ ë°ì´í„° í™•ì¸
            full_index = build_corpus_index(config.paths.data_dir)
            emotion_counts = Counter([item["emotion"] for item in full_index])
            if accelerator.is_main_process:
                print(f"ì „ì²´ í´ë˜ìŠ¤ ë¶„í¬: {dict(emotion_counts)}")
            
            # ê°€ì¥ ì ì€ í´ë˜ìŠ¤ì˜ ìƒ˜í”Œ ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •
            min_samples = min(emotion_counts.values())
            max_samples_per_class = min(min_samples * 2, 1000)
            if accelerator.is_main_process:
                print(f"í´ë˜ìŠ¤ë‹¹ ìµœëŒ€ ìƒ˜í”Œ ìˆ˜ë¥¼ {max_samples_per_class}ê°œë¡œ ì œí•œí•©ë‹ˆë‹¤.")
            
            # ê· í˜• ì¡íŒ ì¸ë±ìŠ¤ ìƒì„±
            index = build_corpus_index(config.paths.data_dir, max_samples_per_class=max_samples_per_class)
            
        valid_paths, invalid_paths = validate_audio_files([item["path"] for item in index])
        
        if invalid_paths and accelerator.is_main_process:
            print(f"ìœ íš¨í•˜ì§€ ì•Šì€ íŒŒì¼ {len(invalid_paths)}ê°œ ì œì™¸")
        
        # ë°ì´í„° ë¶„í• 
        if config.data.use_large_dataset:
            (train_paths, train_labels), (val_paths, val_labels), (test_paths, test_labels) = \
                split_large_dataset(
                    index,
                    val_speaker_ratio=0.2,
                    test_speaker_ratio=0.2,
                    val_content_ratio=0.2,
                    test_content_ratio=0.2,
                )
            train_speakers = sorted(set([item["speaker"] for item in index if item["path"] in train_paths]))
        else:
            (train_paths, train_labels), (val_paths, val_labels), (test_paths, test_labels) = \
                split_speaker_and_content(
                    index,
                    val_content_ratio=0.2,
                    test_content_ratio=0.2,
                    val_speaker_ratio=0.2,
                    test_speaker_ratio=0.2,
                )
            train_speakers = sorted({extract_speaker_id(p, config.paths.data_dir) for p in train_paths})
        
        num_speakers = len(train_speakers)
        if accelerator.is_main_process:
            print(f"ğŸ” í™”ì ìˆ˜: {num_speakers}")

        # ëª¨ë¸ ìƒì„±
        model, processor = create_model_and_processor(num_speakers=num_speakers)
        enable_last_k_blocks(model, last_k=15)

        if accelerator.is_main_process:
            print(f"\nğŸ“Š ë¶„í•  ê²°ê³¼:")
            print(f"  Train: {len(train_paths)}ê°œ")
            print(f"  Validation: {len(val_paths)}ê°œ")
            print(f"  Test: {len(test_paths)}ê°œ")

            train_emotion_dist = Counter(train_labels)
            val_emotion_dist = Counter(val_labels)
            test_emotion_dist = Counter(test_labels)
            
            print(f"\nğŸ“ˆ ê°ì •ë³„ ë¶„í¬:")
            print(f"  Train: {dict(train_emotion_dist)}")
            print(f"  Validation: {dict(val_emotion_dist)}")
            print(f"  Test: {dict(test_emotion_dist)}")
        
        # ë°ì´í„°ì…‹ ìƒì„±
        train_dataset = EmotionDataset(train_paths, train_labels, processor, is_training=True)
        val_dataset = EmotionDataset(val_paths, val_labels, processor, is_training=False)
        test_dataset = EmotionDataset(test_paths, test_labels, processor, is_training=False)
        
        # ë°ì´í„°ë¡œë” ìƒì„± (train : shuffle=True drop_last=True, val/test : shuffle=False, drop_last=False)
        train_loader = DataLoader(
            train_dataset, 
            batch_size=config.training.batch_size,
            shuffle=True,
            collate_fn=collate_fn,
            drop_last=True
        )
        
        val_loader = DataLoader(
            val_dataset,
            batch_size=config.training.batch_size,
            shuffle=False,
            collate_fn=collate_fn,
            drop_last=False,
        )

        test_loader = DataLoader(
            test_dataset,
            batch_size=config.training.batch_size,
            shuffle=False,
            collate_fn=collate_fn,
            drop_last=False,
        )

        model, train_loader, val_loader, test_loader = accelerator.prepare(
            model, train_loader, val_loader, test_loader
        )
        
        # í›ˆë ¨ ì‹¤í–‰
        try:
            best_model_state = train_model_accelerate(
                accelerator, 
                model, 
                train_loader, 
                val_loader, 
                num_epochs=config.training.num_epochs, 
                learning_rate=config.training.learning_rate
            )
            
            # ìµœì¢… í…ŒìŠ¤íŠ¸ í‰ê°€ (main processì—ì„œë§Œ)
            if accelerator.is_main_process:
                if best_model_state is not None:
                    print("\nâœ… ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì•˜ë˜ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...")
                    unwrapped_model = accelerator.unwrap_model(model)
                    unwrapped_model.load_state_dict(best_model_state)
                else:
                    print("\nâš ï¸ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì„ ì°¾ì§€ ëª»í•´, ë§ˆì§€ë§‰ ìƒíƒœì˜ ëª¨ë¸ë¡œ í‰ê°€ ë° ì €ì¥ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
                    unwrapped_model = accelerator.unwrap_model(model)

                print(f"\nğŸ§ª ìµœì¢… í…ŒìŠ¤íŠ¸ í‰ê°€...")
                # test_results = evaluate_model_accelerate(accelerator, model, test_loader, is_training=False)
            
            if accelerator.is_main_process:
                # print(f"\nğŸ¯ ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
                # print(f"   - ì •í™•ë„: {test_results['accuracy']:.4f}")
                # print(f"   - F1 ìŠ¤ì½”ì–´: {test_results['f1']:.4f}")
                # print(f"   - ì†ì‹¤: {test_results['loss']:.4f}")
                
                # # ìƒì„¸ ë¶„ë¥˜ ë¦¬í¬íŠ¸
                # print(f"\nğŸ“‹ ìƒì„¸ ë¶„ë¥˜ ë¦¬í¬íŠ¸:")
                # report = classification_report(
                #     test_results['true_labels'], 
                #     test_results['predictions'],
                #     target_names=config.model.emotion_labels,
                #     digits=4
                # )
                # print(report)
                
                # í•™ìŠµëœ ëª¨ë¸ ì €ì¥
                print(f"\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘...")
                output_dir = config.paths.output_dir
                os.makedirs(output_dir, exist_ok=True)

                model_save_path = os.path.join(output_dir, "Adversary_class4_v3_LargeDataset_MultiGPU_batch8_real_adv_lambda_0.75_20_epoch_spk_id_normal_last_15_class_weight_label_smoothing0.1")
                os.makedirs(model_save_path, exist_ok=True)
                
                try:
                    unwrapped_model.save_pretrained(model_save_path)
                    processor.save_pretrained(model_save_path)
                except Exception as e:
                    print(f"âŒ ëª¨ë¸ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    torch.save(unwrapped_model.state_dict(), os.path.join(model_save_path, "model.pt"))
                
                print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_save_path}")
                print(f"\nğŸ‰ Multi-GPU í›ˆë ¨ ì™„ë£Œ!")
                print(f"   ì‚¬ìš©ëœ GPU: {accelerator.num_processes}ê°œ")
                print(f"   ì €ì¥ëœ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸: python test_my_voice.py your_audio.wav --model_path {model_save_path}")
            
        except KeyboardInterrupt:
            if accelerator.is_main_process:
                print(f"\nâ¹ï¸  í›ˆë ¨ì´ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            if accelerator.is_main_process:
                print(f"\nâŒ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                traceback.print_exc()
        
        if accelerator.is_main_process:
            logger.info("âœ… Multi-GPU í›ˆë ¨ ì™„ë£Œ")
    finally:
        if accelerator.is_main_process:
            # WandB ì„¸ì…˜ ì¢…ë£Œ
            print("\nğŸ§¹ ë’·ì •ë¦¬ ë° WandB ì„¸ì…˜ ì¢…ë£Œ...")
            wandb.finish()

if __name__ == "__main__":
    main()
