import numpy as np
from typing import Tuple, List, Optional, Literal, Dict, Any, Union, overload
from collections import Counter
import re
import os
import random
from tqdm import tqdm

EMOTION_LABELS = ["Anxious", "Dry", "Kind", "Other"]

# script.txt Í∞êÏ†ï Îß§Ìïë
SCRIPT_EMOTION_MAPPING = {
    "NEUTRAL": "Other",
    "ANXIOUS": "Anxious", 
    "KIND": "Kind",
    "DRY": "Dry"
}

def extract_korean_and_punct(text: str) -> str:
    """
    Ï£ºÏñ¥ÏßÑ Î¨∏ÏûêÏó¥ÏóêÏÑú ÌïúÍ∏Ä, ÏâºÌëú, Ïò®Ï†ê Îì±Îßå Ï∂îÏ∂ú (ÌäπÏàòÎßàÏª§ Ï†úÍ±∞)
    Ïòà: 'Î™©Ïù¥ ÎßàÎ•¥Îã§.|||HL Îã§||M Ïù¥Î£®ÏóàÎã§.' -> 'Î™©Ïù¥ ÎßàÎ•¥Îã§. Îã§ Ïù¥Î£®ÏóàÎã§.'
    """
    # ÌïúÍ∏Ä, ÏâºÌëú, Ïò®Ï†ê, Í≥µÎ∞±Îßå ÎÇ®Í∏∞Í∏∞
    import re
    # ÌäπÏàòÎßàÏª§ Ï†úÍ±∞: '|||HL', '||M' Îì±
    text = re.sub(r'\|{2,}\w*', '', text)
    # ÌïúÍ∏Ä, ÏâºÌëú, Ïò®Ï†ê, Í≥µÎ∞±Îßå ÎÇ®Í∏∞Í∏∞
    filtered = re.sub(r'[^Í∞Ä-Ìû£.,?\s]', '', text)
    # Í≥µÎ∞± Ï†ïÎ¶¨
    filtered = re.sub(r'\s+', ' ', filtered).strip()
    return filtered

@overload
def parse_script_file(script_file_path: str, with_sentence: Literal[False] = False) -> Dict[str, str]: ...

@overload  
def parse_script_file(script_file_path: str, with_sentence: Literal[True] = True) -> Tuple[Dict[str, str], Dict[str, str]]: ...

def parse_script_file(script_file_path: str, with_sentence: bool = False) -> Union[Dict[str, str], Tuple[Dict[str, str], Dict[str, str]]]:
    """
    script.txt ÌååÏùºÏùÑ ÌååÏã±ÌïòÏó¨ ÌååÏùºÎ™Ö -> Í∞êÏ†ï Îß§Ìïë ÎîïÏÖîÎÑàÎ¶¨ Î∞òÌôò
    
    Args:
        script_file_path: script.txt ÌååÏùº Í≤ΩÎ°ú
        with_sentence: TrueÏãú Î¨∏Ïû• Îß§ÌïëÎèÑ Ìï®Íªò Î∞òÌôò
        
    Returns:
        with_sentence=False: Dict[ÌååÏùºÎ™Ö(ÌôïÏû•Ïûê Ï†úÏô∏), Í∞êÏ†ï]
        with_sentence=True: (emotion_mapping, sentence_mapping)
    """
    emotion_mapping = {}
    sentence_mapping = {}  # ÌååÏùºÎ™Ö -> Î¨∏Ïû• Îß§Ìïë
    
    try:
        with open(script_file_path, 'r', encoding='utf-8') as f:
            lines = [line.rstrip() for line in f]
            i = 0
            while i < len(lines):
                line = lines[i].strip()
                if not line:
                    i += 1
                    continue
                # F0002_000001 NEUTRAL #ÏßÄÎ¨∏ ÌòïÌÉúÏóêÏÑú ÌååÏùºÎ™ÖÍ≥º Í∞êÏ†ïÎßå Ï∂îÏ∂ú
                if re.match(r'^[FM]\d+_\d+\s+\w+', line):
                    parts = line.split()
                    if len(parts) >= 2:
                        filename = parts[0]
                        emotion_raw = parts[1]
                        emotion = SCRIPT_EMOTION_MAPPING.get(emotion_raw, "Other")
                        emotion_mapping[filename] = emotion
                        
                        # with_sentence=TrueÏùº ÎïåÎßå Î¨∏Ïû• Ï∂îÏ∂ú
                        if with_sentence and i + 1 < len(lines):
                            orig_line = lines[i + 1].strip()
                            clean_sentence = extract_korean_and_punct(orig_line)
                            sentence_mapping[filename] = clean_sentence
                    i += 2  # Îã§Ïùå Î∏îÎ°ùÏúºÎ°ú Ïù¥Îèô
                else:
                    i += 1
    except Exception as e:
        print(f"‚ùå script.txt ÌååÏã± Ïò§Î•ò: {e}")

    if with_sentence:
        return emotion_mapping, sentence_mapping
    return emotion_mapping

def build_large_corpus_index(data_dir: str,
                            accept_exts={'.wav', '.flac'},
                            max_samples_per_class: Optional[int] = None,
                            with_sentence: bool = False) -> List[Dict[str, Any]]:
    """
    large Îç∞Ïù¥ÌÑ∞ÏÖã Ï†ÑÏö© Ïù∏Îç±Ïä§ ÏÉùÏÑ± Ìï®Ïàò
    /data/ghdrnjs/SER/large/large/F0001,F0002,M0001,M0002... Íµ¨Ï°∞
    Í∞Å ÌôîÏûê Ìè¥Îçî ÏïàÏóê script.txtÏôÄ wav ÌååÏùºÎì§Ïù¥ Ï°¥Ïû¨
    """
    index = []
    emotion_counts = {emotion: 0 for emotion in EMOTION_LABELS}
    
    # ÌôîÏûê Ìè¥ÎçîÎì§ Ïä§Ï∫î (F0001~F0004, M0001~M0004 Îì±)
    speaker_folders = sorted([d for d in os.listdir(data_dir) 
                             if os.path.isdir(os.path.join(data_dir, d)) 
                             and re.match(r'^[FM]\d+$', d)])
    
    if not speaker_folders:
        print(f"‚ùå ÌôîÏûê Ìè¥ÎçîÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {data_dir}")
        return []
    
    print(f"ÔøΩ Î∞úÍ≤¨Îêú ÌôîÏûê Ìè¥Îçî: {speaker_folders}")
    
    for speaker in tqdm(speaker_folders, desc="Large Îç∞Ïù¥ÌÑ∞ÏÖã Ïù∏Îç±Ïä§ Íµ¨Ï∂ï"):
        speaker_dir = os.path.join(data_dir, speaker)
        
        # Í∞Å ÌôîÏûê Ìè¥Îçî ÎÇ¥Ïùò script.txt ÌååÏã±
        script_file_path = os.path.join(speaker_dir, "script.txt")
        if not os.path.exists(script_file_path):
            print(f"‚ö†Ô∏è script.txtÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {script_file_path}")
            continue
        
        print(f"üìñ {speaker} script.txt ÌååÏã± Ï§ë...")
        if not with_sentence:
            emotion_mapping = parse_script_file(script_file_path)
            sentence_mapping = {}
        else:
            emotion_mapping, sentence_mapping = parse_script_file(script_file_path, with_sentence=True)

        # Ìï¥Îãπ ÌôîÏûê Ìè¥ÎçîÏóêÏÑú wav ÌååÏùºÎì§ Ïä§Ï∫î
        wav_files = []
        for root, _, files in os.walk(speaker_dir):
            for file in files:
                if any(file.lower().endswith(ext) for ext in accept_exts):
                    wav_files.append(os.path.join(root, file))
        
        for audio_path in wav_files:
            # ÌååÏùºÎ™ÖÏóêÏÑú ÌôïÏû•Ïûê Ï†úÍ±∞ (F0002_000001.wav -> F0002_000001)
            filename_no_ext = os.path.splitext(os.path.basename(audio_path))[0]
            
            # script.txtÏóêÏÑú Í∞êÏ†ï Ï†ïÎ≥¥ Ï°∞Ìöå
            emotion = emotion_mapping.get(filename_no_ext, "Other")
            
            # ÌÅ¥ÎûòÏä§Î≥Ñ ÏµúÎåÄ ÏÉòÌîå Ïàò Ï†úÌïú
            if max_samples_per_class and emotion_counts[emotion] >= max_samples_per_class:
                continue
            
            # Ïª®ÌÖêÏ∏† ID Ï∂îÏ∂ú (F0002_000001 -> 000001)
            content_match = re.search(r'_(\d+)$', filename_no_ext)
            content_id = int(content_match.group(1)) if content_match else 0
            
            # Ïù∏Îç±Ïä§ Ìï≠Î™© ÏÉùÏÑ±
            item = {
                "path": audio_path,
                "emotion": emotion,
                "speaker": speaker,  # ÌôîÏûê Ìè¥ÎçîÎ™Ö ÏÇ¨Ïö©
                "content_id": content_id,
                "source": "large"
            }
            
            # with_sentence=TrueÏùº Îïå Î¨∏Ïû• Ï†ïÎ≥¥ Ï∂îÍ∞Ä
            if with_sentence:
                sentence = sentence_mapping.get(filename_no_ext, "")
                item["sentence"] = sentence
                
            index.append(item)
            emotion_counts[emotion] += 1
    
    print(f"‚úÖ Large Îç∞Ïù¥ÌÑ∞ÏÖã Ïù∏Îç±Ïä§ ÏôÑÎ£å - Ï¥ù {len(index)}Í∞ú ÏÉòÌîå")
    print(f"üìä Í∞êÏ†ïÎ≥Ñ Î∂ÑÌè¨: {dict(emotion_counts)}")
    print(f"üë• ÌôîÏûêÎ≥Ñ Î∂ÑÌè¨: {Counter([item['speaker'] for item in index])}")
    
    return index

def balance_large_dataset(index: List[Dict[str, Any]], 
                         balance_ratio: float = 0.3) -> List[Dict[str, Any]]:
    """
    Large Îç∞Ïù¥ÌÑ∞ÏÖãÏùò ÌÅ¥ÎûòÏä§ Î∂àÍ∑†Ìòï Ìï¥Í≤∞
    Other ÌÅ¥ÎûòÏä§Í∞Ä ÎßéÏúºÎØÄÎ°ú ÎπÑÏú® Ï°∞Ï†ï
    
    Args:
        index: build_large_corpus_index Í≤∞Í≥º
        balance_ratio: Other ÌÅ¥ÎûòÏä§ ÎåÄÎπÑ Îã§Î•∏ ÌÅ¥ÎûòÏä§Îì§Ïùò ÎπÑÏú® (0.3 = OtherÏùò 30% ÏàòÏ§Ä)
    """
    emotion_groups = {emotion: [] for emotion in EMOTION_LABELS}
    
    # Í∞êÏ†ïÎ≥ÑÎ°ú ÏÉòÌîå Í∑∏Î£πÌïë
    for item in index:
        emotion_groups[item["emotion"]].append(item)
    
    print(f"üéØ ÌÅ¥ÎûòÏä§ Í∑†Ìòï Ï°∞Ï†ï (Other ÎåÄÎπÑ ÎπÑÏú®: {balance_ratio})")
    
    # Other ÌÅ¥ÎûòÏä§ Í∞úÏàòÎ•º Í∏∞Ï§ÄÏúºÎ°ú Îã§Î•∏ ÌÅ¥ÎûòÏä§Îì§ Í∞úÏàò Í≤∞Ï†ï
    other_count = len(emotion_groups["Other"])
    target_other_count = other_count  # OtherÎäî Í∑∏ÎåÄÎ°ú Ïú†ÏßÄÌïòÍ±∞ÎÇò ÌïÑÏöîÏãú Ï°∞Ï†ï
    target_non_other_count = int(other_count * balance_ratio)
    
    balanced_index = []
    
    for emotion, samples in emotion_groups.items():
        if emotion == "Other":
            # OtherÎäî Ï†ÑÏ≤¥ ÎòêÎäî Ï°∞Ï†ïÎêú ÏàòÎßåÌÅº ÏÇ¨Ïö©
            selected = samples[:target_other_count] if len(samples) > target_other_count else samples
        else:
            # Îã§Î•∏ Í∞êÏ†ïÎì§ÏùÄ balance_ratioÏóê Îî∞Îùº Ï°∞Ï†ï
            if len(samples) >= target_non_other_count:
                selected = random.sample(samples, target_non_other_count)
            else:
                selected = samples  # ÏÉòÌîåÏù¥ Î∂ÄÏ°±ÌïòÎ©¥ Î™®Îëê ÏÇ¨Ïö©
        
        balanced_index.extend(selected)
        print(f"  {emotion}: {len(selected)}Í∞ú (ÏõêÎ≥∏: {len(samples)}Í∞ú)")
    
    return balanced_index

def balance_by_undersampling_majority(index: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Îç∞Ïù¥ÌÑ∞ÏÖãÏùò ÌÅ¥ÎûòÏä§ Î∂àÍ∑†ÌòïÏùÑ Ìï¥Í≤∞Ìï©ÎãàÎã§.
    Îã§Ïàò ÌÅ¥ÎûòÏä§Ïù∏ 'Other'Î•º ÏÜåÏàò ÌÅ¥ÎûòÏä§Îì§Ïùò ÌèâÍ∑† Í∞úÏàòÏóê ÎßûÏ∂∞ Ïñ∏ÎçîÏÉòÌîåÎßÅÌï©ÎãàÎã§.
    
    Args:
        index: ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ Ïù∏Îç±Ïä§
    """
    emotion_groups = {emotion: [] for emotion in EMOTION_LABELS}
    for item in index:
        emotion_groups[item["emotion"]].append(item)

    # 'Other'Î•º Ï†úÏô∏Ìïú ÏÜåÏàò ÌÅ¥ÎûòÏä§Îì§Ïùò ÌèâÍ∑† ÏÉòÌîå ÏàòÎ•º Í≥ÑÏÇ∞
    non_other_counts = [len(samples) for emotion, samples in emotion_groups.items() if emotion != "Other"]
    if not non_other_counts:
        return index # 'Other' Ïô∏Ïóê ÌÅ¥ÎûòÏä§Í∞Ä ÏóÜÏúºÎ©¥ ÏõêÎ≥∏ Î∞òÌôò
        
    target_count = int(sum(non_other_counts) / len(non_other_counts))
    
    print(f"üéØ ÌÅ¥ÎûòÏä§ Í∑†Ìòï Ï°∞Ï†ï (Ïñ∏ÎçîÏÉòÌîåÎßÅ)")
    print(f"   'Other' ÌÅ¥ÎûòÏä§Î•º Îã§Î•∏ ÌÅ¥ÎûòÏä§ ÌèâÍ∑† Í∞úÏàòÏù∏ {target_count}Í∞úÎ°ú Ï°∞Ï†ïÌï©ÎãàÎã§.")

    balanced_index = []
    
    # 'Other' ÌÅ¥ÎûòÏä§Î•º Î™©Ìëú Í∞úÏàòÎßåÌÅº ÎûúÎç§ ÏÉòÌîåÎßÅ
    if 'Other' in emotion_groups and len(emotion_groups['Other']) > target_count:
        other_samples = random.sample(emotion_groups['Other'], target_count)
        balanced_index.extend(other_samples)
        print(f"  Other: {len(other_samples)}Í∞ú (ÏõêÎ≥∏: {len(emotion_groups['Other'])}Í∞ú)")
    else:
        # 'Other'Í∞Ä ÏóÜÍ±∞ÎÇò Ïù¥ÎØ∏ Î™©ÌëúÏπòÎ≥¥Îã§ Ï†ÅÏúºÎ©¥ Í∑∏ÎåÄÎ°ú ÏÇ¨Ïö©
        balanced_index.extend(emotion_groups.get('Other', []))

    # 'Other'Í∞Ä ÏïÑÎãå ÌÅ¥ÎûòÏä§Îì§ÏùÄ Î™®Îëê ÏÇ¨Ïö©
    for emotion, samples in emotion_groups.items():
        if emotion != "Other":
            balanced_index.extend(samples)
            print(f"  {emotion}: {len(samples)}Í∞ú (ÏõêÎ≥∏: {len(samples)}Í∞ú)")
            
    random.shuffle(balanced_index) # Îç∞Ïù¥ÌÑ∞ ÏàúÏÑú ÏÑûÍ∏∞
    return balanced_index

@overload
def split_large_dataset(
    index: List[Dict[str, Any]],
    val_speaker_ratio: float = 0.2,
    test_speaker_ratio: float = 0.2,
    val_content_ratio: float = 0.2,
    test_content_ratio: float = 0.2,
    seed: int = 42,
    with_sentence: Literal[False] = False,
) -> Tuple[Tuple[List[str], List[str]],
           Tuple[List[str], List[str]],
           Tuple[List[str], List[str]]]: ...

@overload
def split_large_dataset(
    index: List[Dict[str, Any]],
    val_speaker_ratio: float = 0.2,
    test_speaker_ratio: float = 0.2,
    val_content_ratio: float = 0.2,
    test_content_ratio: float = 0.2,
    seed: int = 42,
    with_sentence: Literal[True] = True,
) -> Tuple[Tuple[List[str], List[str], List[str]],
           Tuple[List[str], List[str], List[str]],
           Tuple[List[str], List[str], List[str]]]: ...

def split_large_dataset(
    index: List[Dict[str, Any]],
    val_speaker_ratio: float = 0.2,
    test_speaker_ratio: float = 0.2,
    val_content_ratio: float = 0.2,
    test_content_ratio: float = 0.2,
    seed: int = 42,
    with_sentence: bool = False,
) -> Union[Tuple[Tuple[List[str], List[str]],
                 Tuple[List[str], List[str]],
                 Tuple[List[str], List[str]]],
           Tuple[Tuple[List[str], List[str], List[str]],
                 Tuple[List[str], List[str], List[str]],
                 Tuple[List[str], List[str], List[str]]]]:
    """
    Large Îç∞Ïù¥ÌÑ∞ÏÖã Ï†ÑÏö© ÌôîÏûê/Ïä§ÌÅ¨Î¶ΩÌä∏ Î∂àÍµêÏ∞® Î∂ÑÌï†
    
    Args:
        index: build_large_corpus_index() Í≤∞Í≥º
        val_speaker_ratio: validationÏö© ÌôîÏûê ÎπÑÏú®
        test_speaker_ratio: testÏö© ÌôîÏûê ÎπÑÏú®  
        val_content_ratio: validationÏö© Ïä§ÌÅ¨Î¶ΩÌä∏ ÎπÑÏú®
        test_content_ratio: testÏö© Ïä§ÌÅ¨Î¶ΩÌä∏ ÎπÑÏú®
        seed: ÎûúÎç§ ÏãúÎìú
        with_sentence: TrueÏãú Î¨∏Ïû• Ï†ïÎ≥¥ÎèÑ Ìï®Íªò Î∞òÌôò
        
    Returns:
        with_sentence=False: ((train_paths, train_labels), (val_paths, val_labels), (test_paths, test_labels))
        with_sentence=True: ((train_paths, train_labels, train_sentences), (val_paths, val_labels, val_sentences), (test_paths, test_labels, test_sentences))
    """
    rng = random.Random(seed)
    
    # Ï†ÑÏ≤¥ ÌôîÏûê Î∞è Ïä§ÌÅ¨Î¶ΩÌä∏ ID Î™©Î°ù
    all_speakers = sorted(set([item["speaker"] for item in index]))
    all_contents = sorted(set([item["content_id"] for item in index]))
    
    print(f"üìä Ï†ÑÏ≤¥ ÌôîÏûê: {len(all_speakers)}Î™Ö {all_speakers}")
    print(f"üìù Ï†ÑÏ≤¥ Ïä§ÌÅ¨Î¶ΩÌä∏: {len(all_contents)}Í∞ú")
    
    # ÌôîÏûê Î∂ÑÌï†
    speakers = all_speakers[:]
    rng.shuffle(speakers)
    n_val_spk = max(1, int(len(speakers) * val_speaker_ratio))
    n_test_spk = max(1, int(len(speakers) * test_speaker_ratio))
    
    val_speakers = set(speakers[:n_val_spk])
    test_speakers = set(speakers[n_val_spk:n_val_spk+n_test_spk])
    train_speakers = set(speakers[n_val_spk+n_test_spk:])
    
    # Ïä§ÌÅ¨Î¶ΩÌä∏ ID Î∂ÑÌï†
    contents = all_contents[:]
    rng.shuffle(contents)
    n_val_content = max(1, int(len(contents) * val_content_ratio))
    n_test_content = max(1, int(len(contents) * test_content_ratio))
    
    val_contents = set(contents[:n_val_content])
    test_contents = set(contents[n_val_content:n_val_content+n_test_content])
    train_contents = set(contents[n_val_content+n_test_content:])
    
    # ÌôîÏûêÏôÄ Ïä§ÌÅ¨Î¶ΩÌä∏ Î™®Îëê Î∂àÍµêÏ∞®Ïù∏ ÏÉòÌîåÎßå ÏÑ†ÌÉù
    train_items = [item for item in index 
                   if item["speaker"] in train_speakers and item["content_id"] in train_contents]
    val_items = [item for item in index 
                 if item["speaker"] in val_speakers and item["content_id"] in val_contents]
    test_items = [item for item in index 
                  if item["speaker"] in test_speakers and item["content_id"] in test_contents]
    
    # Í≤∞Í≥º Ï∂úÎ†•
    def summarize_large(name, items, speakers_set, contents_set):
        spks = sorted(set([item["speaker"] for item in items]))
        cids = sorted(set([item["content_id"] for item in items]))
        emo_cnt = Counter([item["emotion"] for item in items])
        print(f"\n[{name}]")
        print(f"  ÏÉòÌîå: {len(items)}Í∞ú")
        print(f"  ÌôîÏûê: {len(spks)}Î™Ö - {spks}")
        print(f"  Ïä§ÌÅ¨Î¶ΩÌä∏: {len(cids)}Í∞ú (ÏòàÏãú: {cids[:10]})")
        print(f"  Í∞êÏ†ïÎ∂ÑÌè¨: {dict(emo_cnt)}")
    
    summarize_large("TRAIN", train_items, train_speakers, train_contents)
    summarize_large("VAL", val_items, val_speakers, val_contents)
    summarize_large("TEST", test_items, test_speakers, test_contents)
    
    # Î∂àÍµêÏ∞® Í≤ÄÏ¶ù
    assert set([item["speaker"] for item in train_items]).isdisjoint(
        set([item["speaker"] for item in val_items + test_items])), "Train ÌôîÏûêÍ∞Ä Val/TestÏôÄ Í≤πÏπ©ÎãàÎã§."
    assert set([item["speaker"] for item in val_items]).isdisjoint(
        set([item["speaker"] for item in test_items])), "Val ÌôîÏûêÍ∞Ä TestÏôÄ Í≤πÏπ©ÎãàÎã§."
    assert set([item["content_id"] for item in train_items]).isdisjoint(
        set([item["content_id"] for item in val_items + test_items])), "Train Ïä§ÌÅ¨Î¶ΩÌä∏Í∞Ä Val/TestÏôÄ Í≤πÏπ©ÎãàÎã§."
    assert set([item["content_id"] for item in val_items]).isdisjoint(
        set([item["content_id"] for item in test_items])), "Val Ïä§ÌÅ¨Î¶ΩÌä∏Í∞Ä TestÏôÄ Í≤πÏπ©ÎãàÎã§."
    
    print("‚úÖ ÌôîÏûê Î∞è Ïä§ÌÅ¨Î¶ΩÌä∏ Î∂àÍµêÏ∞® Í≤ÄÏ¶ù ÏôÑÎ£å!")
    
    # ÏµúÏ¢Ö Î¶¨Ïä§Ìä∏ Î≥ÄÌôò
    if with_sentence:
        def to_xy_with_sentence(items):
            paths = [item["path"] for item in items]
            emotions = [item["emotion"] for item in items]
            sentences = [item.get("sentence", "") for item in items]
            return paths, emotions, sentences
        
        return to_xy_with_sentence(train_items), to_xy_with_sentence(val_items), to_xy_with_sentence(test_items)
    else:
        def to_xy(items):
            return [item["path"] for item in items], [item["emotion"] for item in items]
        
        return to_xy(train_items), to_xy(val_items), to_xy(test_items)

def simple_augmentation(audio: np.ndarray, sample_rate: int) -> np.ndarray:
    """Í∞ÑÎã®Ìïú Ïò§ÎîîÏò§ Ï¶ùÍ∞ï (NumPy 2.x Ìò∏Ìôò)"""
    if np.random.random() < 0.3:  # 30% ÌôïÎ•†Î°ú ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä
        noise = np.random.normal(0, 0.005, audio.shape)
        audio = audio + noise
    
    if np.random.random() < 0.3:  # 30% ÌôïÎ•†Î°ú Î≥ºÎ•® Ï°∞Ï†ï
        volume_factor = np.random.uniform(0.8, 1.2)
        audio = audio * volume_factor
    
    return audio





def extract_number_from_filename(filename: str, type: Literal['content', 'emotion'] = 'emotion') -> Optional[int]:
    try:
        if type == "content":
            # ÌååÏùºÎ™ÖÏóêÏÑú ÎßàÏßÄÎßâ Ïà´Ïûê Í∑∏Î£π Ï†ÑÏ≤¥Î•º Ï∂îÏ∂ú (Ïòà: F2001_000123.wav -> 123)
            match = re.search(r'_(\d+)\.wav$', os.path.basename(filename))
            if match:
                return int(match.group(1))
            return None
        else:
            # F..._...xxxD.wav ÏóêÏÑú ÎßàÏßÄÎßâ Ïà´Ïûê DÎ•º Ï∂îÏ∂ú
            match = re.search(r'_(\d+)\.wav$', os.path.basename(filename))
            if match:
                return int(match.group(1)) % 10
            return None
    except (ValueError, AttributeError):
        return None



def get_emotion_from_filename(filename: str) -> Optional[str]:
    """ÌååÏùºÎ™ÖÏóêÏÑú Î≤àÌò∏Î•º Ï∂îÏ∂úÌïòÏó¨ Í∞êÏ†ï ÎùºÎ≤® Î∞òÌôò"""
    file_num = extract_number_from_filename(filename, type="content")
    if file_num is None:
        return None
        
    if 21 <= file_num <= 30:
        return "Anxious"
    elif 31 <= file_num <= 40:
        return "Kind"
    elif 141 <= file_num <= 150:
        return "Dry"
    else:
        return "Other"


# Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤¥Î•º Ïä§Ï∫îÌï¥ÏÑú (Í≤ΩÎ°ú, Í∞êÏ†ï, ÌôîÏûê, Ïä§ÌÅ¨Î¶ΩÌä∏ID) Ïù∏Îç±Ïä§ ÏÉùÏÑ±
def build_corpus_index(data_dir: str,
                       accept_exts={'.wav', '.flac'},
                       require_emotion=True,
                       max_samples_per_class=None) -> List[Dict[str, Any]]:
    """
    return: [{"path": p, "emotion": e, "speaker": s, "content_id": c}, ...]
    max_samples_per_class: ÌÅ¥ÎûòÏä§Îãπ ÏµúÎåÄ ÏÉòÌîå Ïàò (NoneÏù¥Î©¥ Ï†úÌïú ÏóÜÏùå)
    """
    index = []
    emotion_counts = {emotion: 0 for emotion in EMOTION_LABELS}  # ÌÅ¥ÎûòÏä§Î≥Ñ Ïπ¥Ïö¥Ìä∏
    
    speakers = sorted([d for d in os.listdir(data_dir)
                       if os.path.isdir(os.path.join(data_dir, d))])
    print(f"üìÅ ÌôîÏûê Ìè¥Îçî Ïàò: {len(speakers)}")

    for spk in tqdm(speakers, desc="Ïù∏Îç±Ïä§ Íµ¨Ï∂ï"):
        spk_dir = os.path.join(data_dir, spk)
        # ÌïòÏúÑ ÎîîÎ†âÌÜ†Î¶¨Î•º Ïû¨Í∑ÄÏ†ÅÏúºÎ°ú ÌÉêÏÉâ (Í∞êÏ†ïÎ≥Ñ Ìè¥Îçî/Îã®Ïùº Ìè¥Îçî Îëò Îã§ ÎåÄÏùë)
        for root, _, files in os.walk(spk_dir):
            for fn in files:
                ext = os.path.splitext(fn)[1].lower()
                if ext not in accept_exts:
                    continue
                path = os.path.join(root, fn)

                # Í∞êÏ†ï ÎùºÎ≤®
                emo = infer_emotion_from_path(path)
                if require_emotion and emo not in EMOTION_LABELS:
                    # Other Í∞êÏ†ïÎèÑ Ìè¨Ìï®ÌïòÎèÑÎ°ù ÏàòÏ†ï
                    emo = "Other"
                
                # ÌÅ¥ÎûòÏä§Î≥Ñ ÏµúÎåÄ ÏÉòÌîå Ïàò Ï†úÌïú
                if max_samples_per_class and emotion_counts[emo] >= max_samples_per_class:
                    continue

                # Ïä§ÌÅ¨Î¶ΩÌä∏(ÎåÄÌôî) ID: ÌååÏùºÎ™ÖÏóêÏÑú Ï∂îÏ∂ú (Í∏∞Ï°¥ Í∑úÏπô Í∑∏ÎåÄÎ°ú)
                cid = extract_number_from_filename(fn, type="content")
                if cid is None:
                    # Ïä§ÌÅ¨Î¶ΩÌä∏ ID ÏóÜÏúºÎ©¥ Ï†úÏô∏(Î∂àÍµêÏ∞® Ï°∞Í±¥ÏùÑ Î≥¥Ïû•ÌïòÍ∏∞ ÏúÑÌï¥)
                    continue

                index.append({
                    "path": path,
                    "emotion": emo,
                    "speaker": spk,
                    "content_id": cid
                })
                emotion_counts[emo] += 1
    
    print(f"‚úÖ Ïù∏Îç±Ïä§ ÏÉòÌîå Ïàò: {len(index)}")
    print(f"üìä ÌÅ¥ÎûòÏä§Î≥Ñ Î∂ÑÌè¨: {dict(emotion_counts)}")
    return index


def split_speaker_and_content(
    index: List[Dict[str, Any]],
    val_content_ratio: float = 0.2,
    test_content_ratio: float = 0.2,
    val_speaker_ratio: float = 0.2,
    test_speaker_ratio: float = 0.2,
    seed: int = 42,
    fixed_val_content_ids: Optional[List[int]] = None,
    fixed_test_content_ids: Optional[List[int]] = None,
) -> Tuple[Tuple[List[str], List[str]],
           Tuple[List[str], List[str]],
           Tuple[List[str], List[str]]]:
    """
    index: build_corpus_index() Î∞òÌôò Î¶¨Ïä§Ìä∏
    Î∞òÌôò: ((train_paths, train_labels), (val_paths, val_labels), (test_paths, test_labels))
    """
    rng = random.Random(seed)

    # Ï†ÑÏ≤¥ Ïä§ÌÅ¨Î¶ΩÌä∏ ID, ÌôîÏûê Î™©Î°ù
    all_contents = sorted(set([it["content_id"] for it in index]))
    all_speakers = sorted(set([it["speaker"] for it in index]))

    # --- 2-1) Ïä§ÌÅ¨Î¶ΩÌä∏(ÎåÄÌôî) Î∂àÍµêÏ∞® ÏÑ∏Ìä∏ ÎßåÎì§Í∏∞
    if fixed_val_content_ids is not None and fixed_test_content_ids is not None:
        val_contents = set(fixed_val_content_ids)
        test_contents = set(fixed_test_content_ids)
        train_contents = set(all_contents) - val_contents - test_contents
    else:
        contents = all_contents[:]
        rng.shuffle(contents)
        n_val = max(1, int(len(contents) * val_content_ratio))
        n_test = max(1, int(len(contents) * test_content_ratio))
        val_contents = set(contents[:n_val])
        test_contents = set(contents[n_val:n_val+n_test])
        train_contents = set(contents[n_val+n_test:])

    # --- 2-2) ÌôîÏûê Î∂àÍµêÏ∞® ÏÑ∏Ìä∏ ÎßåÎì§Í∏∞
    speakers = all_speakers[:]
    rng.shuffle(speakers)
    n_val_spk = max(1, int(len(speakers) * val_speaker_ratio))
    n_test_spk = max(1, int(len(speakers) * test_speaker_ratio))
    val_speakers = set(speakers[:n_val_spk])
    test_speakers = set(speakers[n_val_spk:n_val_spk+n_test_spk])
    train_speakers = set(speakers[n_val_spk+n_test_spk:])

    # --- 2-3) ÍµêÏßëÌï© Ï†úÍ±∞: Îëê Ï°∞Í±¥(ÌôîÏûê ÏÑ∏Ìä∏, Ïä§ÌÅ¨Î¶ΩÌä∏ ÏÑ∏Ìä∏)ÏùÑ ÎèôÏãúÏóê ÎßåÏ°±ÌïòÎäî ÏÉòÌîåÎßå Ï±ÑÌÉù
    train_items = [it for it in index
                   if it["speaker"] in train_speakers and it["content_id"] in train_contents]
    val_items   = [it for it in index
                   if it["speaker"] in val_speakers and it["content_id"] in val_contents]
    test_items  = [it for it in index
                   if it["speaker"] in test_speakers and it["content_id"] in test_contents]

    # --- 2-4) Ï†êÍ≤Ä Ï∂úÎ†•
    def summarize(name, items):
        spks = sorted(set([it["speaker"] for it in items]))
        cids = sorted(set([it["content_id"] for it in items]))
        emo_cnt = Counter([it["emotion"] for it in items])
        print(f"\n[{name}] ÏÉòÌîå: {len(items)}, ÌôîÏûê: {len(spks)}, Ïä§ÌÅ¨Î¶ΩÌä∏ID: {len(cids)}")
        print(f"  Í∞êÏ†ïÎ∂ÑÌè¨: {dict(emo_cnt)}")
        print(f"  ÏòàÏãú ÌôîÏûê(ÏµúÎåÄ 10): {spks[:10]}")
        print(f"  ÏòàÏãú Ïä§ÌÅ¨Î¶ΩÌä∏ID(ÏµúÎåÄ 20): {cids[:20]}")

    summarize("TRAIN", train_items)
    summarize("VAL",   val_items)
    summarize("TEST",  test_items)

    # --- 2-5) ÍµêÏ∞® Í≤ÄÏ¶ù: ÌôîÏûê/Ïä§ÌÅ¨Î¶ΩÌä∏ Î∂àÍµêÏ∞® Ïó¨Î∂Ä ÌôïÏù∏
    assert set([it["speaker"] for it in train_items]).isdisjoint(set([it["speaker"] for it in val_items + test_items])), \
        "Train ÌôîÏûêÍ∞Ä Val/TestÏôÄ Í≤πÏπ©ÎãàÎã§."
    assert set([it["speaker"] for it in val_items]).isdisjoint(set([it["speaker"] for it in test_items])), \
        "Val ÌôîÏûêÍ∞Ä TestÏôÄ Í≤πÏπ©ÎãàÎã§."
    assert set([it["content_id"] for it in train_items]).isdisjoint(set([it["content_id"] for it in val_items + test_items])), \
        "Train Ïä§ÌÅ¨Î¶ΩÌä∏IDÍ∞Ä Val/TestÏôÄ Í≤πÏπ©ÎãàÎã§."
    assert set([it["content_id"] for it in val_items]).isdisjoint(set([it["content_id"] for it in test_items])), \
        "Val Ïä§ÌÅ¨Î¶ΩÌä∏IDÍ∞Ä TestÏôÄ Í≤πÏπ©ÎãàÎã§."

    # --- 2-6) ÏµúÏ¢Ö Î¶¨Ïä§Ìä∏ Î≥ÄÌôò
    def to_xy(items):
        return [it["path"] for it in items], [it["emotion"] for it in items]

    return to_xy(train_items), to_xy(val_items), to_xy(test_items)


def load_dataset_subset(data_dir: str, max_per_class: int) -> Tuple[List[str], List[str]]:
    audio_paths = []
    labels = []
    emotion_counts = {label: 0 for label in EMOTION_LABELS}
    
    person_folders = sorted([f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))])
    print(f"üìÅ Î∞úÍ≤¨Îêú person Ìè¥Îçî: {len(person_folders)}Í∞ú")
    
    for person_folder in tqdm(person_folders, desc="Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎî© Ï§ë"):
        wav_path = os.path.join(data_dir, person_folder, "wav_48000")
        if not os.path.exists(wav_path):
            continue
        
        for audio_file in os.listdir(wav_path):
            if not audio_file.lower().endswith('.wav'):
                continue
            
            emotion_label = get_emotion_from_filename(audio_file)
            if emotion_label and emotion_counts[emotion_label] < max_per_class:
                audio_paths.append(os.path.join(wav_path, audio_file))
                labels.append(emotion_label)
                emotion_counts[emotion_label] += 1
        
        if all(count >= max_per_class for count in emotion_counts.values()):
            break

    print(f"\nüìä Î°úÎìúÎêú Îç∞Ïù¥ÌÑ∞ Î∂ÑÌè¨ (Îπ†Î•∏ ÌÖåÏä§Ìä∏Ïö©):")
    for emotion, count in emotion_counts.items():
        percentage = (count / len(audio_paths) * 100) if len(audio_paths) > 0 else 0
        print(f"  {emotion}: {count}Í∞ú ({percentage:.1f}%)")
            
    return audio_paths, labels


# (ÌïÑÏàò) ÌôîÏûê ID Ï∂îÏ∂ú: data_dir Î∞îÎ°ú ÏïÑÎûò 1Îã®Í≥Ñ Ìè¥ÎçîÎ™ÖÏù¥ ÌôîÏûê
def extract_speaker_id(audio_path: str, data_dir: str) -> str:
    rel = os.path.relpath(audio_path, data_dir)
    spk = rel.split(os.sep)[0]
    return spk



def build_speaker_mapping(train_paths, data_dir):
    train_speakers = sorted({extract_speaker_id(p, data_dir) for p in train_paths})
    spk2id = {spk: i for i, spk in enumerate(train_speakers)}
    return spk2id



# (ÏÑ†ÌÉù) Í≤ΩÎ°úÏóêÏÑú Í∞êÏ†ï ÎùºÎ≤® Ï∂îÎ°† (Ìè¥ÎçîÎ™ÖÏóê Anxious/Kind/DryÍ∞Ä ÏûàÏúºÎ©¥ Í∑∏Í±∏ ÏÇ¨Ïö©)
def infer_emotion_from_path(audio_path: str) -> Optional[str]:
    parts = os.path.normpath(audio_path).split(os.sep)
    for p in reversed(parts):
        if p in EMOTION_LABELS:
            return p
    # Ìè¥ÎçîÎ™ÖÏóê ÏóÜÏúºÎ©¥ ÌååÏùºÎ™Ö Í∑úÏπôÏúºÎ°ú Ï∂îÎ°† (Í∏∞Ï°¥ Ìï®Ïàò)
    return get_emotion_from_filename(os.path.basename(audio_path))





