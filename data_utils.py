import numpy as np
from typing import Tuple, List, Optional, Literal, Dict, Any, Union, overload
from collections import Counter
import re
import os
import random
from tqdm import tqdm

EMOTION_LABELS = ["Anxious", "Dry", "Kind", "Other"]

# script.txt ê°ì • ë§¤í•‘
SCRIPT_EMOTION_MAPPING = {
    "NEUTRAL": "Other",
    "ANXIOUS": "Anxious", 
    "KIND": "Kind",
    "DRY": "Dry"
}

def extract_korean_and_punct(text: str) -> str:
    """
    ì£¼ì–´ì§„ ë¬¸ìì—´ì—ì„œ í•œê¸€, ì‰¼í‘œ, ì˜¨ì  ë“±ë§Œ ì¶”ì¶œ (íŠ¹ìˆ˜ë§ˆì»¤ ì œê±°)
    ì˜ˆ: 'ëª©ì´ ë§ˆë¥´ë‹¤.|||HL ë‹¤||M ì´ë£¨ì—ˆë‹¤.' -> 'ëª©ì´ ë§ˆë¥´ë‹¤. ë‹¤ ì´ë£¨ì—ˆë‹¤.'
    """
    # í•œê¸€, ì‰¼í‘œ, ì˜¨ì , ê³µë°±ë§Œ ë‚¨ê¸°ê¸°
    import re
    # íŠ¹ìˆ˜ë§ˆì»¤ ì œê±°: '|||HL', '||M' ë“±
    text = re.sub(r'\|{2,}\w*', '', text)
    # í•œê¸€, ì‰¼í‘œ, ì˜¨ì , ê³µë°±ë§Œ ë‚¨ê¸°ê¸°
    filtered = re.sub(r'[^ê°€-í£.,?\s]', '', text)
    # ê³µë°± ì •ë¦¬
    filtered = re.sub(r'\s+', ' ', filtered).strip()
    return filtered

@overload
def parse_script_file(script_file_path: str, with_sentence: Literal[False] = False) -> Dict[str, str]: ...

@overload  
def parse_script_file(script_file_path: str, with_sentence: Literal[True] = True) -> Tuple[Dict[str, str], Dict[str, str]]: ...

def parse_script_file(script_file_path: str, with_sentence: bool = False) -> Union[Dict[str, str], Tuple[Dict[str, str], Dict[str, str]]]:
    """
    script.txt íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ íŒŒì¼ëª… -> ê°ì • ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜
    
    Args:
        script_file_path: script.txt íŒŒì¼ ê²½ë¡œ
        with_sentence: Trueì‹œ ë¬¸ì¥ ë§¤í•‘ë„ í•¨ê»˜ ë°˜í™˜
        
    Returns:
        with_sentence=False: Dict[íŒŒì¼ëª…(í™•ì¥ì ì œì™¸), ê°ì •]
        with_sentence=True: (emotion_mapping, sentence_mapping)
    """
    emotion_mapping = {}
    sentence_mapping = {}  # íŒŒì¼ëª… -> ë¬¸ì¥ ë§¤í•‘
    
    try:
        with open(script_file_path, 'r', encoding='utf-8') as f:
            lines = [line.rstrip() for line in f]
            i = 0
            while i < len(lines):
                line = lines[i].strip()
                if not line:
                    i += 1
                    continue
                # F0002_000001 NEUTRAL #ì§€ë¬¸ í˜•íƒœì—ì„œ íŒŒì¼ëª…ê³¼ ê°ì •ë§Œ ì¶”ì¶œ
                if re.match(r'^[FM]\d+_\d+\s+\w+', line):
                    parts = line.split()
                    if len(parts) >= 2:
                        filename = parts[0]
                        emotion_raw = parts[1]
                        emotion = SCRIPT_EMOTION_MAPPING.get(emotion_raw, "Other")
                        emotion_mapping[filename] = emotion
                        
                        # with_sentence=Trueì¼ ë•Œë§Œ ë¬¸ì¥ ì¶”ì¶œ
                        if with_sentence and i + 1 < len(lines):
                            orig_line = lines[i + 1].strip()
                            clean_sentence = extract_korean_and_punct(orig_line)
                            sentence_mapping[filename] = clean_sentence
                    i += 2  # ë‹¤ìŒ ë¸”ë¡ìœ¼ë¡œ ì´ë™
                else:
                    i += 1
    except Exception as e:
        print(f"âŒ script.txt íŒŒì‹± ì˜¤ë¥˜: {e}")

    if with_sentence:
        return emotion_mapping, sentence_mapping
    return emotion_mapping

def build_large_corpus_index(data_dir: str,
                            accept_exts={'.wav', '.flac'},
                            max_samples_per_class: Optional[int] = None,
                            with_sentence: bool = False) -> List[Dict[str, Any]]:
    """
    large ë°ì´í„°ì…‹ ì „ìš© ì¸ë±ìŠ¤ ìƒì„± í•¨ìˆ˜
    /data/ghdrnjs/SER/large/large/F0001,F0002,M0001,M0002... êµ¬ì¡°
    ê° í™”ì í´ë” ì•ˆì— script.txtì™€ wav íŒŒì¼ë“¤ì´ ì¡´ì¬
    """
    index = []
    emotion_counts = {emotion: 0 for emotion in EMOTION_LABELS}
    
    # í™”ì í´ë”ë“¤ ìŠ¤ìº” (F0001~F0004, M0001~M0004 ë“±)
    speaker_folders = sorted([d for d in os.listdir(data_dir) 
                             if os.path.isdir(os.path.join(data_dir, d)) 
                             and re.match(r'^[FM]\d+$', d)])
    
    if not speaker_folders:
        print(f"âŒ í™”ì í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_dir}")
        return []
    
    print(f"ï¿½ ë°œê²¬ëœ í™”ì í´ë”: {speaker_folders}")
    
    for speaker in tqdm(speaker_folders, desc="Large ë°ì´í„°ì…‹ ì¸ë±ìŠ¤ êµ¬ì¶•"):
        speaker_dir = os.path.join(data_dir, speaker)
        
        # ê° í™”ì í´ë” ë‚´ì˜ script.txt íŒŒì‹±
        script_file_path = os.path.join(speaker_dir, "script.txt")
        if not os.path.exists(script_file_path):
            print(f"âš ï¸ script.txtë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {script_file_path}")
            continue
        
        print(f"ğŸ“– {speaker} script.txt íŒŒì‹± ì¤‘...")
        if not with_sentence:
            emotion_mapping = parse_script_file(script_file_path)
            sentence_mapping = {}
        else:
            emotion_mapping, sentence_mapping = parse_script_file(script_file_path, with_sentence=True)

        # í•´ë‹¹ í™”ì í´ë”ì—ì„œ wav íŒŒì¼ë“¤ ìŠ¤ìº”
        wav_files = []
        for root, _, files in os.walk(speaker_dir):
            for file in files:
                if any(file.lower().endswith(ext) for ext in accept_exts):
                    wav_files.append(os.path.join(root, file))
        
        for audio_path in wav_files:
            # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±° (F0002_000001.wav -> F0002_000001)
            filename_no_ext = os.path.splitext(os.path.basename(audio_path))[0]
            
            # script.txtì—ì„œ ê°ì • ì •ë³´ ì¡°íšŒ
            emotion = emotion_mapping.get(filename_no_ext, "Other")
            
            # í´ë˜ìŠ¤ë³„ ìµœëŒ€ ìƒ˜í”Œ ìˆ˜ ì œí•œ
            if max_samples_per_class and emotion_counts[emotion] >= max_samples_per_class:
                continue
            
            # ì»¨í…ì¸  ID ì¶”ì¶œ (F0002_000001 -> 000001)
            content_match = re.search(r'_(\d+)$', filename_no_ext)
            content_id = int(content_match.group(1)) if content_match else 0
            
            # ì¸ë±ìŠ¤ í•­ëª© ìƒì„±
            item = {
                "path": audio_path,
                "emotion": emotion,
                "speaker": speaker,  # í™”ì í´ë”ëª… ì‚¬ìš©
                "content_id": content_id,
                "source": "large"
            }
            
            # with_sentence=Trueì¼ ë•Œ ë¬¸ì¥ ì •ë³´ ì¶”ê°€
            if with_sentence:
                sentence = sentence_mapping.get(filename_no_ext, "")
                item["sentence"] = sentence
                
            index.append(item)
            emotion_counts[emotion] += 1
    
    print(f"âœ… Large ë°ì´í„°ì…‹ ì¸ë±ìŠ¤ ì™„ë£Œ - ì´ {len(index)}ê°œ ìƒ˜í”Œ")
    print(f"ğŸ“Š ê°ì •ë³„ ë¶„í¬: {dict(emotion_counts)}")
    print(f"ğŸ‘¥ í™”ìë³„ ë¶„í¬: {Counter([item['speaker'] for item in index])}")
    
    return index

def balance_large_dataset(index: List[Dict[str, Any]], 
                         balance_ratio: float = 0.3) -> List[Dict[str, Any]]:
    """
    Large ë°ì´í„°ì…‹ì˜ í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°
    Other í´ë˜ìŠ¤ê°€ ë§ìœ¼ë¯€ë¡œ ë¹„ìœ¨ ì¡°ì •
    
    Args:
        index: build_large_corpus_index ê²°ê³¼
        balance_ratio: Other í´ë˜ìŠ¤ ëŒ€ë¹„ ë‹¤ë¥¸ í´ë˜ìŠ¤ë“¤ì˜ ë¹„ìœ¨ (0.3 = Otherì˜ 30% ìˆ˜ì¤€)
    """
    emotion_groups = {emotion: [] for emotion in EMOTION_LABELS}
    
    # ê°ì •ë³„ë¡œ ìƒ˜í”Œ ê·¸ë£¹í•‘
    for item in index:
        emotion_groups[item["emotion"]].append(item)
    
    print(f"ğŸ¯ í´ë˜ìŠ¤ ê· í˜• ì¡°ì • (Other ëŒ€ë¹„ ë¹„ìœ¨: {balance_ratio})")
    
    # Other í´ë˜ìŠ¤ ê°œìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ë¥¸ í´ë˜ìŠ¤ë“¤ ê°œìˆ˜ ê²°ì •
    other_count = len(emotion_groups["Other"])
    target_other_count = other_count  # OtherëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ê±°ë‚˜ í•„ìš”ì‹œ ì¡°ì •
    target_non_other_count = int(other_count * balance_ratio)
    
    balanced_index = []
    
    for emotion, samples in emotion_groups.items():
        if emotion == "Other":
            # OtherëŠ” ì „ì²´ ë˜ëŠ” ì¡°ì •ëœ ìˆ˜ë§Œí¼ ì‚¬ìš©
            selected = samples[:target_other_count] if len(samples) > target_other_count else samples
        else:
            # ë‹¤ë¥¸ ê°ì •ë“¤ì€ balance_ratioì— ë”°ë¼ ì¡°ì •
            if len(samples) >= target_non_other_count:
                selected = random.sample(samples, target_non_other_count)
            else:
                selected = samples  # ìƒ˜í”Œì´ ë¶€ì¡±í•˜ë©´ ëª¨ë‘ ì‚¬ìš©
        
        balanced_index.extend(selected)
        print(f"  {emotion}: {len(selected)}ê°œ (ì›ë³¸: {len(samples)}ê°œ)")
    
    return balanced_index

def balance_by_undersampling_majority(index: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    ë°ì´í„°ì…‹ì˜ í´ë˜ìŠ¤ ë¶ˆê· í˜•ì„ í•´ê²°í•©ë‹ˆë‹¤.
    ë‹¤ìˆ˜ í´ë˜ìŠ¤ì¸ 'Other'ë¥¼ ì†Œìˆ˜ í´ë˜ìŠ¤ë“¤ì˜ í‰ê·  ê°œìˆ˜ì— ë§ì¶° ì–¸ë”ìƒ˜í”Œë§í•©ë‹ˆë‹¤.
    
    Args:
        index: ì›ë³¸ ë°ì´í„° ì¸ë±ìŠ¤
    """
    emotion_groups = {emotion: [] for emotion in EMOTION_LABELS}
    for item in index:
        emotion_groups[item["emotion"]].append(item)

    # 'Other'ë¥¼ ì œì™¸í•œ ì†Œìˆ˜ í´ë˜ìŠ¤ë“¤ì˜ í‰ê·  ìƒ˜í”Œ ìˆ˜ë¥¼ ê³„ì‚°
    non_other_counts = [len(samples) for emotion, samples in emotion_groups.items() if emotion != "Other"]
    if not non_other_counts:
        return index # 'Other' ì™¸ì— í´ë˜ìŠ¤ê°€ ì—†ìœ¼ë©´ ì›ë³¸ ë°˜í™˜
        
    target_count = int(sum(non_other_counts) / len(non_other_counts))
    
    print(f"ğŸ¯ í´ë˜ìŠ¤ ê· í˜• ì¡°ì • (ì–¸ë”ìƒ˜í”Œë§)")
    print(f"   'Other' í´ë˜ìŠ¤ë¥¼ ë‹¤ë¥¸ í´ë˜ìŠ¤ í‰ê·  ê°œìˆ˜ì¸ {target_count}ê°œë¡œ ì¡°ì •í•©ë‹ˆë‹¤.")

    balanced_index = []
    
    # 'Other' í´ë˜ìŠ¤ë¥¼ ëª©í‘œ ê°œìˆ˜ë§Œí¼ ëœë¤ ìƒ˜í”Œë§
    if 'Other' in emotion_groups and len(emotion_groups['Other']) > target_count:
        other_samples = random.sample(emotion_groups['Other'], target_count)
        balanced_index.extend(other_samples)
        print(f"  Other: {len(other_samples)}ê°œ (ì›ë³¸: {len(emotion_groups['Other'])}ê°œ)")
    else:
        # 'Other'ê°€ ì—†ê±°ë‚˜ ì´ë¯¸ ëª©í‘œì¹˜ë³´ë‹¤ ì ìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        balanced_index.extend(emotion_groups.get('Other', []))

    # 'Other'ê°€ ì•„ë‹Œ í´ë˜ìŠ¤ë“¤ì€ ëª¨ë‘ ì‚¬ìš©
    for emotion, samples in emotion_groups.items():
        if emotion != "Other":
            balanced_index.extend(samples)
            print(f"  {emotion}: {len(samples)}ê°œ (ì›ë³¸: {len(samples)}ê°œ)")
            
    random.shuffle(balanced_index) # ë°ì´í„° ìˆœì„œ ì„ê¸°
    return balanced_index

@overload
def split_large_dataset(
    index: List[Dict[str, Any]],
    val_speaker_ratio: float = 0.2,
    test_speaker_ratio: float = 0.2,
    val_content_ratio: float = 0.2,
    test_content_ratio: float = 0.2,
    seed: int = 42,
    with_sentence: Literal[False] = False,
) -> Tuple[Tuple[List[str], List[str]],
           Tuple[List[str], List[str]],
           Tuple[List[str], List[str]]]: ...

@overload
def split_large_dataset(
    index: List[Dict[str, Any]],
    val_speaker_ratio: float = 0.2,
    test_speaker_ratio: float = 0.2,
    val_content_ratio: float = 0.2,
    test_content_ratio: float = 0.2,
    seed: int = 42,
    with_sentence: Literal[True] = True,
) -> Tuple[Tuple[List[str], List[str], List[str]],
           Tuple[List[str], List[str], List[str]],
           Tuple[List[str], List[str], List[str]]]: ...

def split_large_dataset(
    index: List[Dict[str, Any]],
    val_speaker_ratio: float = 0.2,
    test_speaker_ratio: float = 0.2,
    val_content_ratio: float = 0.2,
    test_content_ratio: float = 0.2,
    seed: int = 42,
    with_sentence: bool = False,
) -> Union[Tuple[Tuple[List[str], List[str]],
                 Tuple[List[str], List[str]],
                 Tuple[List[str], List[str]]],
           Tuple[Tuple[List[str], List[str], List[str]],
                 Tuple[List[str], List[str], List[str]],
                 Tuple[List[str], List[str], List[str]]]]:
    """
    Large ë°ì´í„°ì…‹ ì „ìš© í™”ì/ìŠ¤í¬ë¦½íŠ¸ ë¶ˆêµì°¨ ë¶„í• 
    
    Args:
        index: build_large_corpus_index() ê²°ê³¼
        val_speaker_ratio: validationìš© í™”ì ë¹„ìœ¨
        test_speaker_ratio: testìš© í™”ì ë¹„ìœ¨  
        val_content_ratio: validationìš© ìŠ¤í¬ë¦½íŠ¸ ë¹„ìœ¨
        test_content_ratio: testìš© ìŠ¤í¬ë¦½íŠ¸ ë¹„ìœ¨
        seed: ëœë¤ ì‹œë“œ
        with_sentence: Trueì‹œ ë¬¸ì¥ ì •ë³´ë„ í•¨ê»˜ ë°˜í™˜
        
    Returns:
        with_sentence=False: ((train_paths, train_labels), (val_paths, val_labels), (test_paths, test_labels))
        with_sentence=True: ((train_paths, train_labels, train_sentences), (val_paths, val_labels, val_sentences), (test_paths, test_labels, test_sentences))
    """
    rng = random.Random(seed)
    
    # ì „ì²´ í™”ì ë° ìŠ¤í¬ë¦½íŠ¸ ID ëª©ë¡
    all_speakers = sorted(set([item["speaker"] for item in index]))
    all_contents = sorted(set([item["content_id"] for item in index]))
    
    print(f"ğŸ“Š ì „ì²´ í™”ì: {len(all_speakers)}ëª… {all_speakers}")
    print(f"ğŸ“ ì „ì²´ ìŠ¤í¬ë¦½íŠ¸: {len(all_contents)}ê°œ")
    
    # í™”ì ë¶„í• 
    speakers = all_speakers[:]
    rng.shuffle(speakers)
    n_val_spk = max(1, int(len(speakers) * val_speaker_ratio))
    n_test_spk = max(1, int(len(speakers) * test_speaker_ratio))
    
    val_speakers = set(speakers[:n_val_spk])
    test_speakers = set(speakers[n_val_spk:n_val_spk+n_test_spk])
    train_speakers = set(speakers[n_val_spk+n_test_spk:])
    
    # ìŠ¤í¬ë¦½íŠ¸ ID ë¶„í• 
    contents = all_contents[:]
    rng.shuffle(contents)
    n_val_content = max(1, int(len(contents) * val_content_ratio))
    n_test_content = max(1, int(len(contents) * test_content_ratio))
    
    val_contents = set(contents[:n_val_content])
    test_contents = set(contents[n_val_content:n_val_content+n_test_content])
    train_contents = set(contents[n_val_content+n_test_content:])
    
    # í™”ìì™€ ìŠ¤í¬ë¦½íŠ¸ ëª¨ë‘ ë¶ˆêµì°¨ì¸ ìƒ˜í”Œë§Œ ì„ íƒ
    train_items = [item for item in index 
                   if item["speaker"] in train_speakers and item["content_id"] in train_contents]
    val_items = [item for item in index 
                 if item["speaker"] in val_speakers and item["content_id"] in val_contents]
    test_items = [item for item in index 
                  if item["speaker"] in test_speakers and item["content_id"] in test_contents]
    
    # ê²°ê³¼ ì¶œë ¥
    def summarize_large(name, items, speakers_set, contents_set):
        spks = sorted(set([item["speaker"] for item in items]))
        cids = sorted(set([item["content_id"] for item in items]))
        emo_cnt = Counter([item["emotion"] for item in items])
        print(f"\n[{name}]")
        print(f"  ìƒ˜í”Œ: {len(items)}ê°œ")
        print(f"  í™”ì: {len(spks)}ëª… - {spks}")
        print(f"  ìŠ¤í¬ë¦½íŠ¸: {len(cids)}ê°œ (ì˜ˆì‹œ: {cids[:10]})")
        print(f"  ê°ì •ë¶„í¬: {dict(emo_cnt)}")
    
    summarize_large("TRAIN", train_items, train_speakers, train_contents)
    summarize_large("VAL", val_items, val_speakers, val_contents)
    summarize_large("TEST", test_items, test_speakers, test_contents)
    
    # ë¶ˆêµì°¨ ê²€ì¦
    assert set([item["speaker"] for item in train_items]).isdisjoint(
        set([item["speaker"] for item in val_items + test_items])), "Train í™”ìê°€ Val/Testì™€ ê²¹ì¹©ë‹ˆë‹¤."
    assert set([item["speaker"] for item in val_items]).isdisjoint(
        set([item["speaker"] for item in test_items])), "Val í™”ìê°€ Testì™€ ê²¹ì¹©ë‹ˆë‹¤."
    assert set([item["content_id"] for item in train_items]).isdisjoint(
        set([item["content_id"] for item in val_items + test_items])), "Train ìŠ¤í¬ë¦½íŠ¸ê°€ Val/Testì™€ ê²¹ì¹©ë‹ˆë‹¤."
    assert set([item["content_id"] for item in val_items]).isdisjoint(
        set([item["content_id"] for item in test_items])), "Val ìŠ¤í¬ë¦½íŠ¸ê°€ Testì™€ ê²¹ì¹©ë‹ˆë‹¤."
    
    print("âœ… í™”ì ë° ìŠ¤í¬ë¦½íŠ¸ ë¶ˆêµì°¨ ê²€ì¦ ì™„ë£Œ!")
    
    # ìµœì¢… ë¦¬ìŠ¤íŠ¸ ë³€í™˜
    if with_sentence:
        def to_xy_with_sentence(items):
            paths = [item["path"] for item in items]
            emotions = [item["emotion"] for item in items]
            sentences = [item.get("sentence", "") for item in items]
            return paths, emotions, sentences
        
        return to_xy_with_sentence(train_items), to_xy_with_sentence(val_items), to_xy_with_sentence(test_items)
    else:
        def to_xy(items):
            return [item["path"] for item in items], [item["emotion"] for item in items]
        
        return to_xy(train_items), to_xy(val_items), to_xy(test_items)

def simple_augmentation(audio: np.ndarray, sample_rate: int) -> np.ndarray:
    """ê°„ë‹¨í•œ ì˜¤ë””ì˜¤ ì¦ê°• (NumPy 2.x í˜¸í™˜)"""
    if np.random.random() < 0.3:  # 30% í™•ë¥ ë¡œ ë…¸ì´ì¦ˆ ì¶”ê°€
        noise = np.random.normal(0, 0.005, audio.shape)
        audio = audio + noise
    
    if np.random.random() < 0.3:  # 30% í™•ë¥ ë¡œ ë³¼ë¥¨ ì¡°ì •
        volume_factor = np.random.uniform(0.8, 1.2)
        audio = audio * volume_factor
    
    return audio





def extract_number_from_filename(filename: str, type: Literal['content', 'emotion'] = 'emotion') -> Optional[int]:
    try:
        if type == "content":
            # íŒŒì¼ëª…ì—ì„œ ë§ˆì§€ë§‰ ìˆ«ì ê·¸ë£¹ ì „ì²´ë¥¼ ì¶”ì¶œ (ì˜ˆ: F2001_000123.wav -> 123)
            match = re.search(r'_(\d+)\.wav$', os.path.basename(filename))
            if match:
                return int(match.group(1))
            return None
        else:
            # F..._...xxxD.wav ì—ì„œ ë§ˆì§€ë§‰ ìˆ«ì Dë¥¼ ì¶”ì¶œ
            match = re.search(r'_(\d+)\.wav$', os.path.basename(filename))
            if match:
                return int(match.group(1)) % 10
            return None
    except (ValueError, AttributeError):
        return None



def get_emotion_from_filename(filename: str) -> Optional[str]:
    """íŒŒì¼ëª…ì—ì„œ ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•˜ì—¬ ê°ì • ë¼ë²¨ ë°˜í™˜"""
    file_num = extract_number_from_filename(filename, type="content")
    if file_num is None:
        return None
        
    if 21 <= file_num <= 30:
        return "Anxious"
    elif 31 <= file_num <= 40:
        return "Kind"
    elif 141 <= file_num <= 150:
        return "Dry"
    else:
        return "Other"


# ë°ì´í„° ì „ì²´ë¥¼ ìŠ¤ìº”í•´ì„œ (ê²½ë¡œ, ê°ì •, í™”ì, ìŠ¤í¬ë¦½íŠ¸ID) ì¸ë±ìŠ¤ ìƒì„±
def build_corpus_index(data_dir: str,
                       accept_exts={'.wav', '.flac'},
                       require_emotion=True,
                       max_samples_per_class=None) -> List[Dict[str, Any]]:
    """
    return: [{"path": p, "emotion": e, "speaker": s, "content_id": c}, ...]
    max_samples_per_class: í´ë˜ìŠ¤ë‹¹ ìµœëŒ€ ìƒ˜í”Œ ìˆ˜ (Noneì´ë©´ ì œí•œ ì—†ìŒ)
    """
    index = []
    emotion_counts = {emotion: 0 for emotion in EMOTION_LABELS}  # í´ë˜ìŠ¤ë³„ ì¹´ìš´íŠ¸
    
    speakers = sorted([d for d in os.listdir(data_dir)
                       if os.path.isdir(os.path.join(data_dir, d))])
    print(f"ğŸ“ í™”ì í´ë” ìˆ˜: {len(speakers)}")

    for spk in tqdm(speakers, desc="ì¸ë±ìŠ¤ êµ¬ì¶•"):
        spk_dir = os.path.join(data_dir, spk)
        # í•˜ìœ„ ë””ë ‰í† ë¦¬ë¥¼ ì¬ê·€ì ìœ¼ë¡œ íƒìƒ‰ (ê°ì •ë³„ í´ë”/ë‹¨ì¼ í´ë” ë‘˜ ë‹¤ ëŒ€ì‘)
        for root, _, files in os.walk(spk_dir):
            for fn in files:
                ext = os.path.splitext(fn)[1].lower()
                if ext not in accept_exts:
                    continue
                path = os.path.join(root, fn)

                # ê°ì • ë¼ë²¨
                emo = infer_emotion_from_path(path)
                if require_emotion and emo not in EMOTION_LABELS:
                    # Other ê°ì •ë„ í¬í•¨í•˜ë„ë¡ ìˆ˜ì •
                    emo = "Other"
                
                # í´ë˜ìŠ¤ë³„ ìµœëŒ€ ìƒ˜í”Œ ìˆ˜ ì œí•œ
                if max_samples_per_class and emotion_counts[emo] >= max_samples_per_class:
                    continue

                # ìŠ¤í¬ë¦½íŠ¸(ëŒ€í™”) ID: íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ (ê¸°ì¡´ ê·œì¹™ ê·¸ëŒ€ë¡œ)
                cid = extract_number_from_filename(fn, type="content")
                if cid is None:
                    # ìŠ¤í¬ë¦½íŠ¸ ID ì—†ìœ¼ë©´ ì œì™¸(ë¶ˆêµì°¨ ì¡°ê±´ì„ ë³´ì¥í•˜ê¸° ìœ„í•´)
                    continue

                index.append({
                    "path": path,
                    "emotion": emo,
                    "speaker": spk,
                    "content_id": cid
                })
                emotion_counts[emo] += 1
    
    print(f"âœ… ì¸ë±ìŠ¤ ìƒ˜í”Œ ìˆ˜: {len(index)}")
    print(f"ğŸ“Š í´ë˜ìŠ¤ë³„ ë¶„í¬: {dict(emotion_counts)}")
    return index


def split_speaker_and_content(
    index: List[Dict[str, Any]],
    val_content_ratio: float = 0.2,
    test_content_ratio: float = 0.2,
    val_speaker_ratio: float = 0.2,
    test_speaker_ratio: float = 0.2,
    seed: int = 42,
    fixed_val_content_ids: Optional[List[int]] = None,
    fixed_test_content_ids: Optional[List[int]] = None,
) -> Tuple[Tuple[List[str], List[str]],
           Tuple[List[str], List[str]],
           Tuple[List[str], List[str]]]:
    """
    index: build_corpus_index() ë°˜í™˜ ë¦¬ìŠ¤íŠ¸
    ë°˜í™˜: ((train_paths, train_labels), (val_paths, val_labels), (test_paths, test_labels))
    """
    rng = random.Random(seed)

    # ì „ì²´ ìŠ¤í¬ë¦½íŠ¸ ID, í™”ì ëª©ë¡
    all_contents = sorted(set([it["content_id"] for it in index]))
    all_speakers = sorted(set([it["speaker"] for it in index]))

    # --- 2-1) ìŠ¤í¬ë¦½íŠ¸(ëŒ€í™”) ë¶ˆêµì°¨ ì„¸íŠ¸ ë§Œë“¤ê¸°
    if fixed_val_content_ids is not None and fixed_test_content_ids is not None:
        val_contents = set(fixed_val_content_ids)
        test_contents = set(fixed_test_content_ids)
        train_contents = set(all_contents) - val_contents - test_contents
    else:
        contents = all_contents[:]
        rng.shuffle(contents)
        n_val = max(1, int(len(contents) * val_content_ratio))
        n_test = max(1, int(len(contents) * test_content_ratio))
        val_contents = set(contents[:n_val])
        test_contents = set(contents[n_val:n_val+n_test])
        train_contents = set(contents[n_val+n_test:])

    # --- 2-2) í™”ì ë¶ˆêµì°¨ ì„¸íŠ¸ ë§Œë“¤ê¸°
    speakers = all_speakers[:]
    rng.shuffle(speakers)
    n_val_spk = max(1, int(len(speakers) * val_speaker_ratio))
    n_test_spk = max(1, int(len(speakers) * test_speaker_ratio))
    val_speakers = set(speakers[:n_val_spk])
    test_speakers = set(speakers[n_val_spk:n_val_spk+n_test_spk])
    train_speakers = set(speakers[n_val_spk+n_test_spk:])

    # --- 2-3) êµì§‘í•© ì œê±°: ë‘ ì¡°ê±´(í™”ì ì„¸íŠ¸, ìŠ¤í¬ë¦½íŠ¸ ì„¸íŠ¸)ì„ ë™ì‹œì— ë§Œì¡±í•˜ëŠ” ìƒ˜í”Œë§Œ ì±„íƒ
    train_items = [it for it in index
                   if it["speaker"] in train_speakers and it["content_id"] in train_contents]
    val_items   = [it for it in index
                   if it["speaker"] in val_speakers and it["content_id"] in val_contents]
    test_items  = [it for it in index
                   if it["speaker"] in test_speakers and it["content_id"] in test_contents]

    # --- 2-4) ì ê²€ ì¶œë ¥
    def summarize(name, items):
        spks = sorted(set([it["speaker"] for it in items]))
        cids = sorted(set([it["content_id"] for it in items]))
        emo_cnt = Counter([it["emotion"] for it in items])
        print(f"\n[{name}] ìƒ˜í”Œ: {len(items)}, í™”ì: {len(spks)}, ìŠ¤í¬ë¦½íŠ¸ID: {len(cids)}")
        print(f"  ê°ì •ë¶„í¬: {dict(emo_cnt)}")
        print(f"  ì˜ˆì‹œ í™”ì(ìµœëŒ€ 10): {spks[:10]}")
        print(f"  ì˜ˆì‹œ ìŠ¤í¬ë¦½íŠ¸ID(ìµœëŒ€ 20): {cids[:20]}")

    summarize("TRAIN", train_items)
    summarize("VAL",   val_items)
    summarize("TEST",  test_items)

    # --- 2-5) êµì°¨ ê²€ì¦: í™”ì/ìŠ¤í¬ë¦½íŠ¸ ë¶ˆêµì°¨ ì—¬ë¶€ í™•ì¸
    assert set([it["speaker"] for it in train_items]).isdisjoint(set([it["speaker"] for it in val_items + test_items])), \
        "Train í™”ìê°€ Val/Testì™€ ê²¹ì¹©ë‹ˆë‹¤."
    assert set([it["speaker"] for it in val_items]).isdisjoint(set([it["speaker"] for it in test_items])), \
        "Val í™”ìê°€ Testì™€ ê²¹ì¹©ë‹ˆë‹¤."
    assert set([it["content_id"] for it in train_items]).isdisjoint(set([it["content_id"] for it in val_items + test_items])), \
        "Train ìŠ¤í¬ë¦½íŠ¸IDê°€ Val/Testì™€ ê²¹ì¹©ë‹ˆë‹¤."
    assert set([it["content_id"] for it in val_items]).isdisjoint(set([it["content_id"] for it in test_items])), \
        "Val ìŠ¤í¬ë¦½íŠ¸IDê°€ Testì™€ ê²¹ì¹©ë‹ˆë‹¤."

    # --- 2-6) ìµœì¢… ë¦¬ìŠ¤íŠ¸ ë³€í™˜
    def to_xy(items):
        return [it["path"] for it in items], [it["emotion"] for it in items]

    return to_xy(train_items), to_xy(val_items), to_xy(test_items)


def load_dataset_subset(data_dir: str, max_per_class: int) -> Tuple[List[str], List[str]]:
    audio_paths = []
    labels = []
    emotion_counts = {label: 0 for label in EMOTION_LABELS}
    
    person_folders = sorted([f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))])
    print(f"ğŸ“ ë°œê²¬ëœ person í´ë”: {len(person_folders)}ê°œ")
    
    for person_folder in tqdm(person_folders, desc="ë°ì´í„°ì…‹ ë¡œë”© ì¤‘"):
        wav_path = os.path.join(data_dir, person_folder, "wav_48000")
        if not os.path.exists(wav_path):
            continue
        
        for audio_file in os.listdir(wav_path):
            if not audio_file.lower().endswith('.wav'):
                continue
            
            emotion_label = get_emotion_from_filename(audio_file)
            if emotion_label and emotion_counts[emotion_label] < max_per_class:
                audio_paths.append(os.path.join(wav_path, audio_file))
                labels.append(emotion_label)
                emotion_counts[emotion_label] += 1
        
        if all(count >= max_per_class for count in emotion_counts.values()):
            break

    print(f"\nğŸ“Š ë¡œë“œëœ ë°ì´í„° ë¶„í¬ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©):")
    for emotion, count in emotion_counts.items():
        percentage = (count / len(audio_paths) * 100) if len(audio_paths) > 0 else 0
        print(f"  {emotion}: {count}ê°œ ({percentage:.1f}%)")
            
    return audio_paths, labels


# (í•„ìˆ˜) í™”ì ID ì¶”ì¶œ: data_dir ë°”ë¡œ ì•„ë˜ 1ë‹¨ê³„ í´ë”ëª…ì´ í™”ì
def extract_speaker_id(audio_path: str, data_dir: str) -> str:
    rel = os.path.relpath(audio_path, data_dir)
    spk = rel.split(os.sep)[0]
    return spk



def build_speaker_mapping(train_paths, data_dir):
    train_speakers = sorted({extract_speaker_id(p, data_dir) for p in train_paths})
    spk2id = {spk: i for i, spk in enumerate(train_speakers)}
    return spk2id



# (ì„ íƒ) ê²½ë¡œì—ì„œ ê°ì • ë¼ë²¨ ì¶”ë¡  (í´ë”ëª…ì— Anxious/Kind/Dryê°€ ìˆìœ¼ë©´ ê·¸ê±¸ ì‚¬ìš©)
def infer_emotion_from_path(audio_path: str) -> Optional[str]:
    parts = os.path.normpath(audio_path).split(os.sep)
    for p in reversed(parts):
        if p in EMOTION_LABELS:
            return p
    # í´ë”ëª…ì— ì—†ìœ¼ë©´ íŒŒì¼ëª… ê·œì¹™ìœ¼ë¡œ ì¶”ë¡  (ê¸°ì¡´ í•¨ìˆ˜)
    return get_emotion_from_filename(os.path.basename(audio_path))





